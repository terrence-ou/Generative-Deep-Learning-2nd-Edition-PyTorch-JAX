{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebf8f39-66c9-47bb-9ddc-5c2627f4a917",
   "metadata": {},
   "source": [
    "# PixelCNN for FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b06cd-02d6-4b0f-bff2-a1b1a05ced68",
   "metadata": {},
   "source": [
    "### In progress\n",
    "\n",
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/02_pixelcnn/pixelcnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393d1206-2d7f-421f-a92c-0a144102c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as Transforms\n",
    "import torchvision.utils as vuitls\n",
    "\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f66fa4-5289-4d7c-a5ca-3d95781ab430",
   "metadata": {},
   "source": [
    "## 0. Train Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d2939e-8ba4-46c0-8017-ca4e0a66ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "PIXEL_LEVELS = 32\n",
    "N_FILTERS = 128\n",
    "RESIDUAL_BLOCKS = 5\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76640e9c-a3eb-4999-b7e5-b64cb0d8e048",
   "metadata": {},
   "source": [
    "## 1. Preparing FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d27d90e-5f5e-49c7-a768-7f453510359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn input image into (label-pixel representatin, pixel-wise labels)\n",
    "def collate_fn(batch):\n",
    "    batch = torch.stack([data[0] for data in batch])\n",
    "    value_step = 1.0 / PIXEL_LEVELS\n",
    "    labels = (batch / value_step).type(torch.int)\n",
    "    imgs = labels.type(torch.float32) * PIXEL_LEVELS\n",
    "    return imgs, labels\n",
    "\n",
    "transform_fn = Transforms.Compose([\n",
    "                    Transforms.ToTensor(),\n",
    "                    Transforms.Resize(IMAGE_SIZE, antialias=True),                        \n",
    "                ])\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "fashion_ds = datasets.FashionMNIST('../../data', \n",
    "                                  train=True, \n",
    "                                  download=True,\n",
    "                                  transform=transform_fn)\n",
    "\n",
    "# Get train dataloader\n",
    "train_loader = DataLoader(fashion_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee97742-720d-4c6b-bf5b-0c0870553f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check dataset\n",
    "def plot_imgs(batch, num_rows=2, num_cols=6):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i in range(num_rows * num_cols):\n",
    "        ax = plt.subplot(num_rows, num_cols, i+1)\n",
    "        ax.imshow(batch[i].permute(1, 2, 0), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "        \n",
    "sample_data = next(iter(train_loader))\n",
    "plot_imgs(sample_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad5f380-0074-4947-ba77-02c5a4bf6ae5",
   "metadata": {},
   "source": [
    "## 2. Build the PixelCNN\n",
    "\n",
    "This PyTorch implementation references pi-tau's GitHub repo: [Link](https://github.com/pi-tau/pixelcnn/blob/master/conv2d_mask.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1200c81a-8683-4290-a31a-ac4180f842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(nn.Conv2d):\n",
    "    \n",
    "    def __init__(self, mask_type, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        kwargs['padding'] = 'same'\n",
    "        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n",
    "\n",
    "        assert mask_type in ['A', 'B'], 'Mask type should be either A or B'\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "        # Creating masks\n",
    "        kh, kw = kernel_size\n",
    "        mask = torch.ones_like(self.weight)\n",
    "        mask[:, :, (kh // 2 + 1):, :] = 0\n",
    "        mask[:, :, (kh // 2), (kw // 2 + 1):] = 0\n",
    "        # If mask type is A, then masking the center pixel\n",
    "        if mask_type == 'A':\n",
    "            mask[:, :, (kh // 2), (kw // 2)] = 0\n",
    "\n",
    "        # Making the mask the non-trainable parameter of the module\n",
    "        self.register_buffer('mask', mask.type(dtype=torch.bool))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.conv2d(x, self.mask * self.weight, self.bias, \n",
    "                        self.stride, self.padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d368b6-96c7-45fa-810c-de35c44b1421",
   "metadata": {},
   "source": [
    "Check the mask in the masked conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e01823c-2bf5-44ee-ab1b-08abaf5192fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask of the conv layer: \n",
      " tensor([[[[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [ True,  True, False, False, False],\n",
      "          [False, False, False, False, False],\n",
      "          [False, False, False, False, False]]]])\n"
     ]
    }
   ],
   "source": [
    "test_conv_layer = MaskedConv2D('A', 1, 1, 5)\n",
    "print(\"Mask of the conv layer: \\n\", test_conv_layer.mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
