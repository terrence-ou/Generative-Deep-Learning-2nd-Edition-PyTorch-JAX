{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebf8f39-66c9-47bb-9ddc-5c2627f4a917",
   "metadata": {},
   "source": [
    "# PixelCNN for FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b06cd-02d6-4b0f-bff2-a1b1a05ced68",
   "metadata": {},
   "source": [
    "### In progress\n",
    "\n",
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/02_pixelcnn/pixelcnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393d1206-2d7f-421f-a92c-0a144102c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as Transforms\n",
    "import torchvision.utils as vuitls\n",
    "\n",
    "import torchinfo\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f66fa4-5289-4d7c-a5ca-3d95781ab430",
   "metadata": {},
   "source": [
    "## 0. Train Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d2939e-8ba4-46c0-8017-ca4e0a66ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "PIXEL_LEVELS = 12\n",
    "N_FILTERS = 128\n",
    "RESIDUAL_BLOCKS = 5\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150\n",
    "LEARNING_RATE = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76640e9c-a3eb-4999-b7e5-b64cb0d8e048",
   "metadata": {},
   "source": [
    "## 1. Preparing FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d27d90e-5f5e-49c7-a768-7f453510359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn input image into (label-pixel representatin, pixel-wise labels)\n",
    "def collate_fn(batch):\n",
    "    batch = torch.stack([data[0] for data in batch])\n",
    "    value_step = 1.0 / PIXEL_LEVELS\n",
    "    labels = (batch / value_step).type(torch.int)\n",
    "    imgs = labels.type(torch.float32) * PIXEL_LEVELS\n",
    "    return imgs, labels\n",
    "\n",
    "transform_fn = Transforms.Compose([\n",
    "                    Transforms.ToTensor(),\n",
    "                    Transforms.Resize(IMAGE_SIZE, antialias=True),                        \n",
    "                ])\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "fashion_ds = datasets.FashionMNIST('../../data', \n",
    "                                  train=True, \n",
    "                                  download=True,\n",
    "                                  transform=transform_fn)\n",
    "\n",
    "# Get train dataloader\n",
    "train_loader = DataLoader(fashion_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee97742-720d-4c6b-bf5b-0c0870553f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check dataset\n",
    "def plot_imgs(batch, num_rows=2, num_cols=6):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i in range(num_rows * num_cols):\n",
    "        ax = plt.subplot(num_rows, num_cols, i+1)\n",
    "        ax.imshow(batch[i].permute(1, 2, 0), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "        \n",
    "sample_data = next(iter(train_loader))\n",
    "plot_imgs(sample_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad5f380-0074-4947-ba77-02c5a4bf6ae5",
   "metadata": {},
   "source": [
    "## 2. Build the PixelCNN\n",
    "\n",
    "This PyTorch implementation references pi-tau's GitHub repo: [Link](https://github.com/pi-tau/pixelcnn/blob/master/conv2d_mask.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1200c81a-8683-4290-a31a-ac4180f842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building MaskedConv2D layer\n",
    "class MaskedConv2D(nn.Conv2d):\n",
    "    \n",
    "    def __init__(self, mask_type, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        kwargs['padding'] = 'same'\n",
    "        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n",
    "\n",
    "        assert mask_type in ['A', 'B'], 'Mask type should be either A or B'\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "        # Creating masks\n",
    "        kh, kw = kernel_size\n",
    "        mask = torch.ones_like(self.weight)\n",
    "        mask[:, :, (kh // 2 + 1):, :] = 0\n",
    "        mask[:, :, (kh // 2), (kw // 2 + 1):] = 0\n",
    "        # If mask type is A, then masking the center pixel\n",
    "        if mask_type == 'A':\n",
    "            mask[:, :, (kh // 2), (kw // 2)] = 0\n",
    "\n",
    "        # Making the mask the non-trainable parameter of the module\n",
    "        self.register_buffer('mask', mask.type(dtype=torch.bool))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.conv2d(x, self.mask * self.weight, self.bias, \n",
    "                        self.stride, self.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e01823c-2bf5-44ee-ab1b-08abaf5192fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \"A\" mask of the conv layer:\n",
      "[[[[ True  True  True  True  True]\n",
      "   [ True  True  True  True  True]\n",
      "   [ True  True False False False]\n",
      "   [False False False False False]\n",
      "   [False False False False False]]]]\n",
      "\n",
      "Type \"B\" mask of the conv layer:\n",
      "[[[[ True  True  True  True  True]\n",
      "   [ True  True  True  True  True]\n",
      "   [ True  True  True False False]\n",
      "   [False False False False False]\n",
      "   [False False False False False]]]]\n"
     ]
    }
   ],
   "source": [
    "# Check the mask in the masked conv layer\n",
    "print(\"Type \\\"A\\\" mask of the conv layer:\")\n",
    "print(MaskedConv2D('A', 1, 1, 5).mask.numpy())\n",
    "\n",
    "print(\"\\nType \\\"B\\\" mask of the conv layer:\")\n",
    "print(MaskedConv2D('B', 1, 1, 5).mask.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb8f94b-00a2-4378-97f0-89df0c676cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=in_channels, \n",
    "                                  out_channels=out_channels // 2,\n",
    "                                  kernel_size=1, padding='valid',\n",
    "                                  stride=1),\n",
    "                        nn.ReLU())\n",
    "\n",
    "        self.pixel_conv = nn.Sequential(\n",
    "                        MaskedConv2D(\n",
    "                            mask_type='B',\n",
    "                            in_channels=out_channels // 2,\n",
    "                            out_channels=out_channels // 2,\n",
    "                            kernel_size=3,\n",
    "                            padding='same'),\n",
    "                        nn.ReLU())\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=out_channels // 2,\n",
    "                                  out_channels=out_channels,\n",
    "                                  kernel_size=1,\n",
    "                                  padding='valid'),\n",
    "                        nn.ReLU())\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_x = self.conv_1(x)\n",
    "        conv_x = self.pixel_conv(conv_x)\n",
    "        conv_x = self.conv_2(conv_x)\n",
    "        return x + conv_x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6023b96-00df-4fa5-877b-abe629115406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the residual block\n",
    "# model = ResidualBlock(4, 4)\n",
    "# torchinfo.summary(model=model, input_size=(1, 4, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c982afc6-62e3-4688-94d2-d50c833edea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "PixelCNN                                 [1, 12, 16, 16]           --\n",
       "├─Sequential: 1-1                        [1, 128, 16, 16]          --\n",
       "│    └─MaskedConv2D: 2-1                 [1, 128, 16, 16]          6,400\n",
       "│    └─ReLU: 2-2                         [1, 128, 16, 16]          --\n",
       "├─Sequential: 1-2                        [1, 128, 16, 16]          --\n",
       "│    └─ResidualBlock: 2-3                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-1              [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-2              [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-3              [1, 128, 16, 16]          8,320\n",
       "│    └─ResidualBlock: 2-4                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-4              [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-5              [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-6              [1, 128, 16, 16]          8,320\n",
       "│    └─ResidualBlock: 2-5                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-7              [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-8              [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-9              [1, 128, 16, 16]          8,320\n",
       "│    └─ResidualBlock: 2-6                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-10             [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-11             [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-12             [1, 128, 16, 16]          8,320\n",
       "│    └─ResidualBlock: 2-7                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-13             [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-14             [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-15             [1, 128, 16, 16]          8,320\n",
       "├─Sequential: 1-3                        [1, 128, 16, 16]          --\n",
       "│    └─Sequential: 2-8                   [1, 128, 16, 16]          --\n",
       "│    │    └─MaskedConv2D: 3-16           [1, 128, 16, 16]          16,512\n",
       "│    │    └─ReLU: 3-17                   [1, 128, 16, 16]          --\n",
       "│    └─Sequential: 2-9                   [1, 128, 16, 16]          --\n",
       "│    │    └─MaskedConv2D: 3-18           [1, 128, 16, 16]          16,512\n",
       "│    │    └─ReLU: 3-19                   [1, 128, 16, 16]          --\n",
       "├─Conv2d: 1-4                            [1, 12, 16, 16]           1,548\n",
       "==========================================================================================\n",
       "Total params: 308,492\n",
       "Trainable params: 308,492\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 78.97\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 3.43\n",
       "Params size (MB): 1.23\n",
       "Estimated Total Size (MB): 4.67\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_filters, num_res_blocks, ouput_size=PIXEL_LEVELS):\n",
    "        super().__init__()\n",
    "        self.masked_conv_1 = nn.Sequential( \n",
    "                                MaskedConv2D(\n",
    "                                    mask_type='A',\n",
    "                                    in_channels=1,\n",
    "                                    out_channels=num_filters,\n",
    "                                    kernel_size=7,\n",
    "                                    padding='same'),\n",
    "                                nn.ReLU()\n",
    "                             )\n",
    "\n",
    "        self.res_convs = nn.Sequential(*[\n",
    "                            ResidualBlock(\n",
    "                                in_channels=num_filters,\n",
    "                                out_channels=num_filters)\n",
    "                            for _ in range(num_res_blocks)])\n",
    "\n",
    "        self.masked_conv_2 = nn.Sequential(*[\n",
    "                                nn.Sequential(\n",
    "                                    MaskedConv2D(\n",
    "                                        mask_type='B',\n",
    "                                        in_channels=num_filters,\n",
    "                                        out_channels=num_filters,\n",
    "                                        kernel_size=1,\n",
    "                                        padding='valid'),\n",
    "                                    nn.ReLU())\n",
    "                                for _ in range(2)],\n",
    "                            )\n",
    "\n",
    "        self.output_conv = nn.Conv2d(in_channels=num_filters,\n",
    "                                     out_channels=ouput_size,\n",
    "                                     kernel_size=1,\n",
    "                                     stride=1,\n",
    "                                     padding='valid')\n",
    "        # We don't need a softmax layer when using CrossEntropy Loss in PyTorch\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.masked_conv_1(x)\n",
    "        x = self.res_convs(x)\n",
    "        x = self.masked_conv_2(x)\n",
    "        x = self.output_conv(x)\n",
    "        return x\n",
    "\n",
    "model = PixelCNN(N_FILTERS, RESIDUAL_BLOCKS)\n",
    "torchinfo.summary(model=model, input_size=(1, 1, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a103523-b6f8-4b1e-a1ba-43e65e03799a",
   "metadata": {},
   "source": [
    "## 3. Define the model, objective, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e468fb7-901c-46e2-84d9-d521e899f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model compiled\n"
     ]
    }
   ],
   "source": [
    "pixel_cnn = PixelCNN(N_FILTERS, RESIDUAL_BLOCKS).to(DEVICE)\n",
    "\n",
    "if torch.__version__.split('.')[0] == '2':\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    # It is important to use eager backend here to avoid\n",
    "    # distribution mismatch in training and predicting\n",
    "    pixel_cnn = torch.compile(pixel_cnn, backend='eager')\n",
    "    print('model compiled')\n",
    "\n",
    "optim = torch.optim.Adam(pixel_cnn.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf5364-4860-4d2c-a202-37096215dbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
