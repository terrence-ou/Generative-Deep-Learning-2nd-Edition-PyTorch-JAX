{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebf8f39-66c9-47bb-9ddc-5c2627f4a917",
   "metadata": {},
   "source": [
    "# PixelCNN for FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b06cd-02d6-4b0f-bff2-a1b1a05ced68",
   "metadata": {},
   "source": [
    "### In progress\n",
    "\n",
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/02_pixelcnn/pixelcnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393d1206-2d7f-421f-a92c-0a144102c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as Transforms\n",
    "\n",
    "import torchinfo\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f66fa4-5289-4d7c-a5ca-3d95781ab430",
   "metadata": {},
   "source": [
    "## 0. Train Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d2939e-8ba4-46c0-8017-ca4e0a66ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "PIXEL_LEVELS = 12\n",
    "N_FILTERS = 128\n",
    "RESIDUAL_BLOCKS = 5\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76640e9c-a3eb-4999-b7e5-b64cb0d8e048",
   "metadata": {},
   "source": [
    "## 1. Preparing FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d27d90e-5f5e-49c7-a768-7f453510359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn input image into (label-pixel representatin, pixel-wise labels)\n",
    "# def collate_fn(batch):\n",
    "#     batch = torch.stack([data[0] for data in batch])\n",
    "#     value_step = 1.0 / PIXEL_LEVELS\n",
    "#     labels = (batch / value_step).type(torch.long)\n",
    "#     imgs = labels.type(torch.float32) / PIXEL_LEVELS\n",
    "#     return imgs, labels\n",
    "\n",
    "def get_dataloader():\n",
    "    transform_fn = Transforms.Compose([\n",
    "                        Transforms.ToTensor(),\n",
    "                        Transforms.Resize(IMAGE_SIZE, antialias=True),                        \n",
    "                    ])\n",
    "    \n",
    "    # Load FashionMNIST dataset\n",
    "    fashion_ds = datasets.FashionMNIST('../../data', \n",
    "                                      train=True, \n",
    "                                      download=True,\n",
    "                                      transform=transform_fn)\n",
    "\n",
    "    # Get train dataloader\n",
    "    train_loader = DataLoader(fashion_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=8)\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee97742-720d-4c6b-bf5b-0c0870553f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check dataset\n",
    "def plot_imgs(batch, num_rows=2, num_cols=6):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i in range(num_rows * num_cols):\n",
    "        ax = plt.subplot(num_rows, num_cols, i+1)\n",
    "        ax.imshow(batch[i].permute(1, 2, 0), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "test_loader = get_dataloader()\n",
    "sample_data = next(iter(test_loader))\n",
    "\n",
    "plot_imgs(sample_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad5f380-0074-4947-ba77-02c5a4bf6ae5",
   "metadata": {},
   "source": [
    "## 2. Build the PixelCNN\n",
    "\n",
    "This PyTorch implementation references pi-tau's GitHub repo: [Link](https://github.com/pi-tau/pixelcnn/blob/master/conv2d_mask.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1200c81a-8683-4290-a31a-ac4180f842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building MaskedConv2D layer\n",
    "class MaskedConv2D(nn.Conv2d):\n",
    "    \n",
    "    def __init__(self, mask_type, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        kwargs['padding'] = 'same'\n",
    "        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n",
    "\n",
    "        assert mask_type in ['A', 'B'], 'Mask type should be either A or B'\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "        # Creating masks\n",
    "        kh, kw = kernel_size\n",
    "        mask = torch.ones_like(self.weight)\n",
    "        mask[:, :, (kh // 2 + 1):, :] = 0\n",
    "        mask[:, :, (kh // 2), (kw // 2 + 1):] = 0\n",
    "        # If mask type is A, then masking the center pixel\n",
    "        if mask_type == 'A':\n",
    "            mask[:, :, (kh // 2), (kw // 2)] = 0\n",
    "\n",
    "        # Making the mask the non-trainable parameter of the module\n",
    "        self.register_buffer('mask', mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.conv2d(x, self.weight * self.mask, \n",
    "                        stride=self.stride, padding=self.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e01823c-2bf5-44ee-ab1b-08abaf5192fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \"A\" mask of the conv layer:\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [1. 1. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]]]\n",
      "\n",
      "Type \"B\" mask of the conv layer:\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Check the mask in the masked conv layer\n",
    "print(\"Type \\\"A\\\" mask of the conv layer:\")\n",
    "print(MaskedConv2D('A', 1, 1, 5).mask.numpy())\n",
    "\n",
    "print(\"\\nType \\\"B\\\" mask of the conv layer:\")\n",
    "print(MaskedConv2D('B', 1, 1, 5).mask.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb8f94b-00a2-4378-97f0-89df0c676cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=in_channels, \n",
    "                                  out_channels=out_channels // 2,\n",
    "                                  kernel_size=1,\n",
    "                                  stride=1),\n",
    "                        nn.ReLU())\n",
    "\n",
    "        self.pixel_conv = nn.Sequential(\n",
    "                        MaskedConv2D(\n",
    "                            mask_type='B',\n",
    "                            in_channels=out_channels // 2,\n",
    "                            out_channels=out_channels // 2,\n",
    "                            kernel_size=3,\n",
    "                            padding='same'),\n",
    "                        nn.ReLU())\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=out_channels // 2,\n",
    "                                  out_channels=out_channels,\n",
    "                                  kernel_size=1),\n",
    "                        nn.ReLU())\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_x = self.conv_1(x)\n",
    "        conv_x = self.pixel_conv(conv_x)\n",
    "        conv_x = self.conv_2(conv_x)\n",
    "        return conv_x + x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6023b96-00df-4fa5-877b-abe629115406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the residual block\n",
    "# model = ResidualBlock(4, 4)\n",
    "# torchinfo.summary(model=model, input_size=(1, 4, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c982afc6-62e3-4688-94d2-d50c833edea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "PixelCNN                                 [1, 1, 16, 16, 12]        --\n",
       "├─Sequential: 1-1                        [1, 128, 16, 16]          --\n",
       "│    └─MaskedConv2D: 2-1                 [1, 128, 16, 16]          6,400\n",
       "│    └─ReLU: 2-2                         [1, 128, 16, 16]          --\n",
       "├─Sequential: 1-2                        [1, 128, 16, 16]          --\n",
       "│    └─ResidualBlock: 2-3                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-1              [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-2              [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-3              [1, 128, 16, 16]          8,320\n",
       "│    └─ResidualBlock: 2-4                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-4              [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-5              [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-6              [1, 128, 16, 16]          8,320\n",
       "│    └─ResidualBlock: 2-5                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-7              [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-8              [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-9              [1, 128, 16, 16]          8,320\n",
       "│    └─ResidualBlock: 2-6                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-10             [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-11             [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-12             [1, 128, 16, 16]          8,320\n",
       "│    └─ResidualBlock: 2-7                [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-13             [1, 64, 16, 16]           8,256\n",
       "│    │    └─Sequential: 3-14             [1, 64, 16, 16]           36,928\n",
       "│    │    └─Sequential: 3-15             [1, 128, 16, 16]          8,320\n",
       "├─Sequential: 1-3                        [1, 128, 16, 16]          --\n",
       "│    └─Sequential: 2-8                   [1, 128, 16, 16]          --\n",
       "│    │    └─MaskedConv2D: 3-16           [1, 128, 16, 16]          16,512\n",
       "│    │    └─ReLU: 3-17                   [1, 128, 16, 16]          --\n",
       "│    └─Sequential: 2-9                   [1, 128, 16, 16]          --\n",
       "│    │    └─MaskedConv2D: 3-18           [1, 128, 16, 16]          16,512\n",
       "│    │    └─ReLU: 3-19                   [1, 128, 16, 16]          --\n",
       "├─Conv2d: 1-4                            [1, 12, 16, 16]           1,548\n",
       "==========================================================================================\n",
       "Total params: 308,492\n",
       "Trainable params: 308,492\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 78.97\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 3.43\n",
       "Params size (MB): 1.23\n",
       "Estimated Total Size (MB): 4.67\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_filters, num_res_blocks, ouput_size=PIXEL_LEVELS):\n",
    "        super().__init__()\n",
    "        self.masked_conv_1 = nn.Sequential( \n",
    "                                MaskedConv2D(\n",
    "                                    mask_type='A',\n",
    "                                    in_channels=1,\n",
    "                                    out_channels=num_filters,\n",
    "                                    kernel_size=7,\n",
    "                                    padding='same'),\n",
    "                                nn.ReLU()\n",
    "                             )\n",
    "\n",
    "        self.res_convs = nn.Sequential(*[\n",
    "                            ResidualBlock(\n",
    "                                in_channels=num_filters,\n",
    "                                out_channels=num_filters)\n",
    "                            for _ in range(num_res_blocks)])\n",
    "\n",
    "        self.masked_conv_2 = nn.Sequential(*[\n",
    "                                nn.Sequential(\n",
    "                                    MaskedConv2D(\n",
    "                                        mask_type='B',\n",
    "                                        in_channels=num_filters,\n",
    "                                        out_channels=num_filters,\n",
    "                                        kernel_size=1,\n",
    "                                        padding='valid'),\n",
    "                                    nn.ReLU())\n",
    "                                for _ in range(2)],\n",
    "                            )\n",
    "\n",
    "        self.output_conv = nn.Conv2d(in_channels=num_filters,\n",
    "                                     out_channels=ouput_size,\n",
    "                                     kernel_size=1,\n",
    "                                     stride=1,\n",
    "                                     padding='valid')\n",
    "        # We don't need a softmax layer when using CrossEntropy Loss in PyTorch\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.masked_conv_1(x)\n",
    "        x = self.res_convs(x)\n",
    "        x = self.masked_conv_2(x)\n",
    "        x = self.output_conv(x)\n",
    "        x = x.reshape(len(x), 1, PIXEL_LEVELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        x = x.permute(0, 1, 3, 4, 2) \n",
    "        return x\n",
    "\n",
    "model = PixelCNN(N_FILTERS, RESIDUAL_BLOCKS)\n",
    "torchinfo.summary(model=model, input_size=(1, 1, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a103523-b6f8-4b1e-a1ba-43e65e03799a",
   "metadata": {},
   "source": [
    "## 3. Define the model, dataloader, objective, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e468fb7-901c-46e2-84d9-d521e899f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn = PixelCNN(N_FILTERS, RESIDUAL_BLOCKS).to(DEVICE)\n",
    "\n",
    "# if torch.__version__.split('.')[0] == '2':\n",
    "#     torch.set_float32_matmul_precision('high')\n",
    "#     # It is important to use eager backend here to avoid\n",
    "#     # distribution mismatch in training and predicting\n",
    "#     pixel_cnn = torch.compile(pixel_cnn, dynamic=True)\n",
    "#     print('model compiled')\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(pixel_cnn.parameters(), lr=5e-4, betas=(0.5, 0.999))\n",
    "\n",
    "train_loader = get_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9093698-308f-46d3-b045-d41e0e2fde53",
   "metadata": {},
   "source": [
    "## 4. Trainer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "615bc215-f7fd-4112-81aa-d442388baa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator:\n",
    "\n",
    "    def __init__(self, num_imgs):\n",
    "        self.num_imgs = num_imgs\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "        return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "    def generate(self, temperature):\n",
    "        model.eval()\n",
    "        \n",
    "        generated_imgs = np.zeros(shape=(self.num_imgs, 1, IMAGE_SIZE, IMAGE_SIZE))\n",
    "        batch, channels, rows, cols = generated_imgs.shape\n",
    "\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                for channel in range(channels):\n",
    "                    with torch.no_grad():\n",
    "                        probs = model(torch.tensor(generated_imgs, dtype=torch.float32).cuda())[:, :, row, col]\n",
    "                    probs = nn.functional.softmax(probs, dim=-1).squeeze()\n",
    "                    probs = probs.detach().cpu().numpy()\n",
    "                    generated_imgs[:, channel, row, col] = [\n",
    "                        self.sample_from(x, temperature) for x in probs\n",
    "                    ]\n",
    "                    generated_imgs[:, channel, row, col] /= PIXEL_LEVELS\n",
    "        return generated_imgs\n",
    "\n",
    "image_generator = ImageGenerator(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7cc8d87-2773-46c8-9173-e74a0deeddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, dataloader, loss_fn, optim):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for imgs, _ in dataloader:\n",
    "        # imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        logits = model(imgs)\n",
    "        logits = logits.reshape(-1, PIXEL_LEVELS)\n",
    "        targets = (imgs.reshape(-1) * PIXEL_LEVELS).long()\n",
    "        loss = loss_fn(logits, targets)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c77c7a90-7220-4b6f-ae86-65bcc699775f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.455699815750122\n",
      "2.455699830754598\n",
      "2.455699821345011\n",
      "2.4556998395284015\n",
      "2.4556998330434165\n",
      "2.4556998330434165\n",
      "2.4556998271942136\n",
      "2.4556998302459716\n",
      "2.4556998299916586\n",
      "2.4556998215993247\n",
      "2.4556998296101886\n",
      "2.455699838511149\n",
      "2.455699834060669\n",
      "2.455699830118815\n",
      "2.4556998297373456\n",
      "2.455699827448527\n",
      "2.4556998329162596\n",
      "2.4556998229980467\n",
      "2.4556998390197755\n",
      "2.4556998291015626\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4556998249053956\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m         generated_imgs \u001b[38;5;241m=\u001b[39m image_generator\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m1.0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(model, dataloader, loss_fn, optim)\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, targets)\n\u001b[1;32m     13\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    loss = trainer(model, train_loader, loss_fn, optim)\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        generated_imgs = image_generator.generate(1.0)\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        for i in range(4):\n",
    "            ax = plt.subplot(2, 2, i+1)\n",
    "            ax.imshow(generated_imgs[i][0], cmap='gray')\n",
    "            ax.axis('off')\n",
    "    plt.show()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc40ed2-6503-4de7-a534-1ad9326f9d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
