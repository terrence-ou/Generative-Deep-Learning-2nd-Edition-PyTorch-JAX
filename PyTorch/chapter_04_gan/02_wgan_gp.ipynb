{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ac02ed-39b6-450a-9cc3-e87f63612f86",
   "metadata": {
    "id": "21ac02ed-39b6-450a-9cc3-e87f63612f86"
   },
   "source": [
    "# WGAN-GP on CelebA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0158ba5-8464-48bc-bb55-b7cdafd397cd",
   "metadata": {
    "id": "f0158ba5-8464-48bc-bb55-b7cdafd397cd"
   },
   "source": [
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/04_gan/02_wgan_gp/wgan_gp.ipynb)\n",
    "- Dataset: [Kaggle](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730e4aeb-8b38-4951-8c3e-c1b9e4918598",
   "metadata": {
    "id": "730e4aeb-8b38-4951-8c3e-c1b9e4918598"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython import display\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as Transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from torchsummary import summary\n",
    "from torcheval import metrics as Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837c6eb-367a-4035-8a80-841dfa5e2c96",
   "metadata": {
    "id": "0837c6eb-367a-4035-8a80-841dfa5e2c96"
   },
   "source": [
    "## 0. Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c2330e-84b4-4cc6-8dd7-facded15de60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c2330e-84b4-4cc6-8dd7-facded15de60",
    "outputId": "83af67bb-b71e-46cf-c877-636eeb42798b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '../../data/CelebFaces/img_align_celeba/img_align_celeba/'\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 128\n",
    "Z_DIM = 128\n",
    "LR = 2e-4\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.9\n",
    "EPOCHS = 100\n",
    "CRITIC_STEPS = 3\n",
    "GP_WEIGHT = 10.0\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe9a65-3309-410a-9d11-a218680300c9",
   "metadata": {
    "id": "6dbe9a65-3309-410a-9d11-a218680300c9"
   },
   "source": [
    "## 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba34ebdd-57ae-4d67-a6bd-8bca5a77ef11",
   "metadata": {
    "id": "ba34ebdd-57ae-4d67-a6bd-8bca5a77ef11"
   },
   "outputs": [],
   "source": [
    "class CelebA(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transform = Transforms.Compose([\n",
    "                Transforms.ToTensor(),\n",
    "                Transforms.Resize(size=IMAGE_SIZE, antialias=True),\n",
    "                Transforms.CenterCrop(size=IMAGE_SIZE),\n",
    "                Transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ])\n",
    "\n",
    "        self.dir = image_dir\n",
    "        self.imgs_files = os.listdir(self.dir)\n",
    "        self.length = len(self.imgs_files)\n",
    "\n",
    "        # Store images in this class to save time in training\n",
    "        self.imgs = torch.zeros(size=(self.length, CHANNELS, IMAGE_SIZE, IMAGE_SIZE))\n",
    "        for i, file_name in enumerate(self.imgs_files):\n",
    "            img = self.transform(Image.open(self.dir + file_name))\n",
    "            self.imgs[i] = img\n",
    "        print(self.imgs.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # output_img = self.transform(Image.open(self.dir + self.imgs[index]))\n",
    "        # return output_img\n",
    "        return self.imgs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6228654-0da9-4dd2-a4e0-c7034aeed1b5",
   "metadata": {
    "id": "b6228654-0da9-4dd2-a4e0-c7034aeed1b5"
   },
   "outputs": [],
   "source": [
    "def get_dataloader():\n",
    "    print('Loading dataset...')\n",
    "    prev_time = time.time()\n",
    "    celeb_data = CelebA(DATA_DIR)\n",
    "    celeb_dataloader = DataLoader(celeb_data, BATCH_SIZE, shuffle=True,\n",
    "                                  num_workers=8, pin_memory=True)\n",
    "    curr_time = time.time()\n",
    "    print('Total loading time {:.2f} min'.format((curr_time - prev_time) / 60))\n",
    "    print('Train data size: ', len(celeb_data))\n",
    "    print('Num. train batchs: ', len(celeb_dataloader))\n",
    "    return celeb_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O8dno5RybywO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "O8dno5RybywO",
    "outputId": "91fd1d23-d13e-45c8-cd68-1ea6fc57c022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "face_dataloader = get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NvaVIkhnsneL",
   "metadata": {
    "id": "NvaVIkhnsneL"
   },
   "outputs": [],
   "source": [
    "def display_imgs(imgs):\n",
    "    plt.figure(figsize=(16, 3))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(vutils.make_grid(imgs[:8], nrow=8, padding=2, normalize=True).detach().cpu(),(1,2,0)))\n",
    "\n",
    "# plot training records\n",
    "def show_records(history):\n",
    "    plt.figure(figsize=(16, 3))\n",
    "    for i, key in enumerate(history):\n",
    "        ax = plt.subplot(1, len(history), i+1)\n",
    "        ax.plot(history[key])\n",
    "        ax.set_title(key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KsJ1nA41b7os",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "KsJ1nA41b7os",
    "outputId": "0c9a1107-3b14-4a9c-8abd-32cad5be1a17"
   },
   "outputs": [],
   "source": [
    "test_sample = next(iter(face_dataloader))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "plt.imshow(np.transpose(vutils.make_grid(test_sample[:36], nrow=6, padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ErOBuhKcQuU",
   "metadata": {
    "id": "6ErOBuhKcQuU"
   },
   "source": [
    "## 2. Building WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YMjTcRyohe5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMjTcRyohe5a",
    "outputId": "cedd794f-ff5b-41de-be59-6098e608df0e"
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        channel_list = [CHANNELS, 64, 128, 256, 512]\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.Sequential()\n",
    "        for i in range(len(channel_list) - 1):\n",
    "            self.conv_layers.add_module(f'conv_{i}',\n",
    "                                        self.get_conv_block(channel_list[i], channel_list[i+1], bool(i)))\n",
    "\n",
    "        # Layers for output -> (Batch_size, 1)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=channel_list[-1], out_channels=1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def get_conv_block(self, in_ch, out_ch, use_dropout):\n",
    "        conv_layer = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=4,\n",
    "                               stride=2, padding=1)\n",
    "        leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        dropout = nn.Dropout2d(0.3)\n",
    "        if use_dropout:\n",
    "            return nn.Sequential(conv_layer, leaky_relu, dropout)\n",
    "        else:\n",
    "            return nn.Sequential(conv_layer, leaky_relu)\n",
    "\n",
    "critic = Critic().to(DEVICE)\n",
    "summary(critic, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KLhvsWHFj6Wk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLhvsWHFj6Wk",
    "outputId": "a5462751-2204-43ab-9ad2-82cd704dd6a7"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "        channel_list = [z_dim, 512, 256, 128, 64]\n",
    "\n",
    "        # Convolution transpose layers\n",
    "        self.trans_conv_layers = nn.Sequential()\n",
    "        for i in range(len(channel_list) - 1):\n",
    "            stride = 2 if i else 1\n",
    "            padding = 1 if i else 0\n",
    "            trans_conv_block = self.get_transpose_conv_block(channel_list[i], channel_list[i + 1],\n",
    "                                                             stride, padding)\n",
    "            self.trans_conv_layers.add_module(f'trans_conv_block_{i}', trans_conv_block)\n",
    "\n",
    "        # Output layers -> (-1, 1, 64, 64)\n",
    "        self.output_layers = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=channel_list[-1], out_channels=CHANNELS,\n",
    "                                   kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], x.shape[-1], 1, 1)\n",
    "        x = self.trans_conv_layers(x)\n",
    "        x = self.output_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def get_transpose_conv_block(self, in_ch, out_ch, stride=2, padding=1):\n",
    "        transpose_conv = nn.ConvTranspose2d(in_channels=in_ch, out_channels=out_ch,\n",
    "                                            kernel_size=4, stride=stride, padding=padding, bias=False)\n",
    "        batch_norm = nn.BatchNorm2d(num_features=out_ch, momentum=0.1)\n",
    "        leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        return nn.Sequential(transpose_conv, batch_norm, leaky_relu)\n",
    "\n",
    "generator = Generator(Z_DIM).to(DEVICE)\n",
    "summary(generator, (Z_DIM,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rHLvBtc_kWEN",
   "metadata": {
    "id": "rHLvBtc_kWEN"
   },
   "outputs": [],
   "source": [
    "class WGAN_GP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generator = Generator(Z_DIM).to(DEVICE)\n",
    "        self.critic = Critic().to(DEVICE)\n",
    "        self.critic_steps = CRITIC_STEPS\n",
    "\n",
    "    def gradient_penalty(self, real_imgs, fake_imgs):\n",
    "        if not self.critic.training:\n",
    "            self.critic.train()\n",
    "        alpha = torch.randn(size=(1,), device=DEVICE)\n",
    "        diff = real_imgs - fake_imgs\n",
    "        interpolates = real_imgs + alpha * diff\n",
    "\n",
    "        interpolates.requires_grad_()\n",
    "        preds = self.critic(interpolates)\n",
    "        grads = autograd.grad(outputs=preds, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones_like(preds),\n",
    "                              create_graph=True, retain_graph=True,\n",
    "                              only_inputs=True)[0]\n",
    "\n",
    "        gp = (torch.norm(grads, dim=1) - 1) ** 2\n",
    "        return gp.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HJ2Vajxbqw2q",
   "metadata": {
    "id": "HJ2Vajxbqw2q"
   },
   "source": [
    "## 3. Define the model, objective, and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wkoWvl_zsYEi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkoWvl_zsYEi",
    "outputId": "0ac1f172-0315-4838-b341-c86a88590758"
   },
   "outputs": [],
   "source": [
    "wgan_gp = WGAN_GP().to(DEVICE)\n",
    "\n",
    "if torch.__version__.split('.')[0] == '2':\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    # It is important to use eager backend here to avoid\n",
    "    # distribution mismatch in training and predicting\n",
    "    wgan_gp = torch.compile(wgan_gp, backend='eager')\n",
    "    print('model compiled')\n",
    "\n",
    "c_optim = torch.optim.AdamW(params=wgan_gp.critic.parameters(),\n",
    "                           lr=LR, betas=[ADAM_BETA_1, ADAM_BETA_2], amsgrad=True)\n",
    "\n",
    "g_optim = torch.optim.AdamW(params=wgan_gp.generator.parameters(),\n",
    "                           lr=LR, betas=[ADAM_BETA_1, ADAM_BETA_2], amsgrad=True)\n",
    "\n",
    "train_metrics = {\n",
    "    'c_loss': Metrics.Mean(),\n",
    "    'c_wass_loss': Metrics.Mean(),\n",
    "    'c_gp': Metrics.Mean(),\n",
    "    'g_loss': Metrics.Mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o-pzU9IR1-4W",
   "metadata": {
    "id": "o-pzU9IR1-4W"
   },
   "source": [
    "## 4. Get dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HScK-T9w2FpU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HScK-T9w2FpU",
    "outputId": "d4bd7339-dca8-424f-9dc5-bba9dd2c6d79"
   },
   "outputs": [],
   "source": [
    "# face_dataloader = get_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bTvH1hLjiRcO",
   "metadata": {
    "id": "bTvH1hLjiRcO"
   },
   "source": [
    "## 5. Trainer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2u-INNOoiUxo",
   "metadata": {
    "id": "2u-INNOoiUxo"
   },
   "outputs": [],
   "source": [
    "def trainer(model, dataloader, c_optim, g_optim, train_metrics):\n",
    "\n",
    "    model.train() # Set model to train mode\n",
    "\n",
    "    for metric in train_metrics.values():\n",
    "        metric.reset()\n",
    "\n",
    "    num_passes = len(dataloader)\n",
    "\n",
    "    for i in tqdm(range(num_passes)):\n",
    "\n",
    "        # 1. Train Critic\n",
    "        for _ in range(model.critic_steps):\n",
    "            c_optim.zero_grad()\n",
    "\n",
    "            # 1.1 Train critic on real data\n",
    "            real_imgs = next(iter(dataloader))\n",
    "            real_imgs = real_imgs.to(DEVICE)\n",
    "            real_preds = model.critic(real_imgs)\n",
    "            # Gradient ascent for real loss, therefore negative\n",
    "            real_loss = -real_preds.mean()\n",
    "\n",
    "            # 1.2 Train critic on fake data\n",
    "            latents = torch.randn(size=(len(real_imgs), Z_DIM), device=DEVICE)\n",
    "            fake_imgs = model.generator(latents)\n",
    "            fake_preds = model.critic(fake_imgs)\n",
    "            # Gradient descent for fake loss, therefore positive\n",
    "            fake_loss = fake_preds.mean()\n",
    "\n",
    "            # 1.3 Gradient penalty\n",
    "            c_gp = model.gradient_penalty(real_imgs, fake_imgs)\n",
    "\n",
    "            # put all losses together\n",
    "            c_wass_loss = fake_loss + real_loss\n",
    "            c_loss = c_wass_loss + GP_WEIGHT * c_gp\n",
    "            c_loss.backward()\n",
    "            c_optim.step()\n",
    "\n",
    "\n",
    "        # 2. Train Generator\n",
    "        g_optim.zero_grad()\n",
    "\n",
    "        latents = torch.randn(size=(len(real_imgs), Z_DIM), device=DEVICE)\n",
    "        fake_imgs = model.generator(latents)\n",
    "        fake_preds = model.critic(fake_imgs)\n",
    "\n",
    "        # Gradient ascent for fake loss, therefore negative\n",
    "        g_loss = -fake_preds.mean()\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "\n",
    "        train_metrics['c_wass_loss'].update(c_wass_loss.detach().cpu())\n",
    "        train_metrics['c_gp'].update(c_gp.detach().cpu())\n",
    "        train_metrics['c_loss'].update(c_loss.detach().cpu())\n",
    "        train_metrics['g_loss'].update(g_loss.detach().cpu())\n",
    "\n",
    "        del real_imgs, real_preds, fake_preds\n",
    "\n",
    "    return fake_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dAWaxlvOqx3C",
   "metadata": {
    "id": "dAWaxlvOqx3C"
   },
   "source": [
    "## 6. Train WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "NtFJUI_orriS",
   "metadata": {
    "id": "NtFJUI_orriS"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1482dff0bd7d4f53b4bddce83840a75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m      4\u001b[0m     prev_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m     generated_imgs \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwgan_gp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     curr_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m train_metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(model, dataloader, c_optim, g_optim, train_metrics)\u001b[0m\n\u001b[1;32m     14\u001b[0m c_optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 1.1 Train critic on real data\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m real_imgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m real_imgs \u001b[38;5;241m=\u001b[39m real_imgs\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     19\u001b[0m real_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcritic(real_imgs)\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1084\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1082\u001b[0m _utils\u001b[38;5;241m.\u001b[39msignal_handling\u001b[38;5;241m.\u001b[39m_set_SIGCHLD_handler()\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_pids_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1117\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# prime the prefetch loop\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers):\n\u001b[0;32m-> 1117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_put_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1362\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1359\u001b[0m     \u001b[38;5;66;03m# not found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1362\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_queues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_queue_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_idx] \u001b[38;5;241m=\u001b[39m (worker_queue_idx,)\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/multiprocessing/queues.py:94\u001b[0m, in \u001b[0;36mQueue.put\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_notempty:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mappend(obj)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_notempty\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/multiprocessing/queues.py:179\u001b[0m, in \u001b[0;36mQueue._start_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m debug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoing self._thread.start()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m debug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m... done self._thread.start()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joincancelled:\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/threading.py:875\u001b[0m, in \u001b[0;36mThread.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_started\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_torch/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    prev_time = time.time()\n",
    "    generated_imgs = trainer(wgan_gp, face_dataloader, c_optim, g_optim, train_metrics)\n",
    "    curr_time = time.time()\n",
    "\n",
    "    for key, value in train_metrics.items():\n",
    "        history[key].append(value.compute().item())\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    print('Epoch: {}\\tepoch time {:.2f} min'.format(i+1, (curr_time - prev_time) / 60))\n",
    "    metrics = [f'{key}: {value.compute().item():.4f} | ' for key, value in train_metrics.items()]\n",
    "    print('\\t', ''.join(metrics))\n",
    "\n",
    "    generated_imgs = generated_imgs.detach().cpu()\n",
    "    display_imgs(generated_imgs)\n",
    "    show_records(history)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        torch.save(wgan_gp.state_dict(), './models/wgan_gp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b530fca-3f37-495d-bebf-a1197610e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan_gp.load_state_dict(torch.load('./models/wgan_gp.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32678a2a-539e-4d4e-8f3a-d57773230f01",
   "metadata": {
    "id": "_fKWLXRHuT8p"
   },
   "source": [
    "## 7. Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162ba2e-5c22-421a-ac5a-f9ba06f498c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_samples = torch.randn(size=(8, Z_DIM), device=DEVICE)\n",
    "wgan_gp.eval()\n",
    "with torch.no_grad():\n",
    "    generated_imgs = wgan_gp.generator(z_samples)\n",
    "generated_imgs = generated_imgs.detach().cpu()\n",
    "display_imgs(generated_imgs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
