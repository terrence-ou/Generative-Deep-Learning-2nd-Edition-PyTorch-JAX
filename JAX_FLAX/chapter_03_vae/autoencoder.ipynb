{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50369926-5286-49e5-86ee-cd0056f63e1d",
   "metadata": {},
   "source": [
    "# AutoEncoders on Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57176e-fbbe-440e-853f-151a584153c8",
   "metadata": {},
   "source": [
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/03_vae/01_autoencoder/autoencoder.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ad78687-57bf-4e8d-b4b2-b8cf82ef8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e06df-d47f-4dc4-a595-c8d020476c0c",
   "metadata": {},
   "source": [
    "## 0. Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33594689-f9e1-45ba-956d-afae8b34be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 1024\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EMBEDDING_DIM = 2\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fdc6a-58db-4ed0-b4cd-7aee5467fc92",
   "metadata": {},
   "source": [
    "## 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "540d3fc1-ea21-477e-9288-408823478ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the image file\n",
    "def preprocess(img):\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    img = tf.pad(img, ((2, 2), (2, 2), (0, 0)), constant_values=0)\n",
    "    return img\n",
    "\n",
    "# get MNIST dataset\n",
    "def get_dataset(num_epochs, batch_size):\n",
    "    # Download MNIST dataset\n",
    "    train_ds = tfds.load('mnist', split='train')\n",
    "    test_ds = tfds.load('mnist', split='test')\n",
    "\n",
    "    # Mapping images as tf tensors\n",
    "    train_ds = train_ds.map(lambda sample: {'image': preprocess(sample['image']),\n",
    "                                            'label': sample['label']})\n",
    "    test_ds = test_ds.map(lambda sample: {'image': preprocess(sample['image']),\n",
    "                                          'label': sample['label']})\n",
    "\n",
    "    # TF dataloader\n",
    "    train_ds = train_ds.repeat(num_epochs).shuffle(1024)\n",
    "    train_ds = train_ds.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "    test_ds = test_ds.shuffle(1024)\n",
    "    test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb880e35-107d-47c0-b0a5-3f27e1723d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "check_train, chech_test = get_dataset(EPOCHS, BATCH_SIZE)\n",
    "print(next(iter(check_train))['image'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886c5d5-2d8b-423c-a1cb-6e459682d140",
   "metadata": {},
   "source": [
    "## 2. Build the AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993bdaf9-0f52-4e0f-98b0-6a16338848b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    latents: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), strides=2)(x)\n",
    "        \n",
    "\n",
    "# Decoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
