{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50369926-5286-49e5-86ee-cd0056f63e1d",
   "metadata": {},
   "source": [
    "# AutoEncoders on Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57176e-fbbe-440e-853f-151a584153c8",
   "metadata": {},
   "source": [
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/03_vae/01_autoencoder/autoencoder.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad78687-57bf-4e8d-b4b2-b8cf82ef8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e06df-d47f-4dc4-a595-c8d020476c0c",
   "metadata": {},
   "source": [
    "## 0. Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33594689-f9e1-45ba-956d-afae8b34be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 2\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fdc6a-58db-4ed0-b4cd-7aee5467fc92",
   "metadata": {},
   "source": [
    "## 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "540d3fc1-ea21-477e-9288-408823478ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the image file\n",
    "def preprocess(img):\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    img = tf.pad(img, ((2, 2), (2, 2), (0, 0)), constant_values=0)\n",
    "    return img\n",
    "\n",
    "# get MNIST dataset\n",
    "def get_dataset(num_epochs, batch_size):\n",
    "    # Download MNIST dataset\n",
    "    train_ds = tfds.load('mnist', split='train')\n",
    "    test_ds = tfds.load('mnist', split='test')\n",
    "\n",
    "    # Mapping images as tf tensors\n",
    "    train_ds = train_ds.map(lambda sample: {'image': preprocess(sample['image']),\n",
    "                                            'label': sample['label']})\n",
    "    test_ds = test_ds.map(lambda sample: {'image': preprocess(sample['image']),\n",
    "                                          'label': sample['label']})\n",
    "\n",
    "    # TF dataloader\n",
    "    train_ds = train_ds.repeat(num_epochs).shuffle(1024)\n",
    "    train_ds = train_ds.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "    test_ds = test_ds.shuffle(1024)\n",
    "    test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb880e35-107d-47c0-b0a5-3f27e1723d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "check_train, chech_test = get_dataset(EPOCHS, BATCH_SIZE)\n",
    "print(next(iter(check_train))['image'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886c5d5-2d8b-423c-a1cb-6e459682d140",
   "metadata": {},
   "source": [
    "## 2. Build the AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "993bdaf9-0f52-4e0f-98b0-6a16338848b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    latents: int\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3), strides=2)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3), strides=2)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=128, kernel_size=(3, 3), strides=2)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = nn.Dense(features=self.latents)(x)\n",
    "        return x\n",
    "\n",
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(features=2048)(x)\n",
    "        x = x.reshape(x.shape[0], 4, 4, 128)\n",
    "        x = nn.ConvTranspose(features=128, kernel_size=(3, 3), strides=(2, 2))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.ConvTranspose(features=64, kernel_size=(3, 3), strides=(2, 2))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.ConvTranspose(features=32, kernel_size=(3, 3), strides=(2, 2))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Conv(features=1, kernel_size=(3, 3), strides=1)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4090b5a4-d17a-48ee-ad78-9b2bca4619f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                                  AE Summary                                                  \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│                       │ AE            │ \u001b[2mfloat32\u001b[0m[1,32,32,1]  │ \u001b[2mfloat32\u001b[0m[1,32,32,1]  │                        │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ encoder               │ Encoder       │ \u001b[2mfloat32\u001b[0m[1,32,32,1]  │ \u001b[2mfloat32\u001b[0m[1,2]        │                        │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ encoder/Conv_0        │ Conv          │ \u001b[2mfloat32\u001b[0m[1,32,32,1]  │ \u001b[2mfloat32\u001b[0m[1,16,16,32] │ bias: \u001b[2mfloat32\u001b[0m[32]      │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[3,3,1,32]      │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m320 \u001b[0m\u001b[1;2m(1.3 KB)\u001b[0m           │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ encoder/Conv_1        │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16,16,32] │ \u001b[2mfloat32\u001b[0m[1,8,8,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]      │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[3,3,32,64]     │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m18,496 \u001b[0m\u001b[1;2m(74.0 KB)\u001b[0m       │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ encoder/Conv_2        │ Conv          │ \u001b[2mfloat32\u001b[0m[1,8,8,64]   │ \u001b[2mfloat32\u001b[0m[1,4,4,128]  │ bias: \u001b[2mfloat32\u001b[0m[128]     │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[3,3,64,128]    │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m73,856 \u001b[0m\u001b[1;2m(295.4 KB)\u001b[0m      │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ encoder/Dense_0       │ Dense         │ \u001b[2mfloat32\u001b[0m[1,2048]     │ \u001b[2mfloat32\u001b[0m[1,2]        │ bias: \u001b[2mfloat32\u001b[0m[2]       │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[2048,2]        │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m4,098 \u001b[0m\u001b[1;2m(16.4 KB)\u001b[0m        │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ decoder               │ Decoder       │ \u001b[2mfloat32\u001b[0m[1,2]        │ \u001b[2mfloat32\u001b[0m[1,32,32,1]  │                        │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ decoder/Dense_0       │ Dense         │ \u001b[2mfloat32\u001b[0m[1,2]        │ \u001b[2mfloat32\u001b[0m[1,2048]     │ bias: \u001b[2mfloat32\u001b[0m[2048]    │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[2,2048]        │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m6,144 \u001b[0m\u001b[1;2m(24.6 KB)\u001b[0m        │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ decoder/ConvTranspos… │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[1,4,4,128]  │ \u001b[2mfloat32\u001b[0m[1,8,8,128]  │ bias: \u001b[2mfloat32\u001b[0m[128]     │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[3,3,128,128]   │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m147,584 \u001b[0m\u001b[1;2m(590.3 KB)\u001b[0m     │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ decoder/ConvTranspos… │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[1,8,8,128]  │ \u001b[2mfloat32\u001b[0m[1,16,16,64] │ bias: \u001b[2mfloat32\u001b[0m[64]      │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[3,3,128,64]    │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m73,792 \u001b[0m\u001b[1;2m(295.2 KB)\u001b[0m      │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ decoder/ConvTranspos… │ ConvTranspose │ \u001b[2mfloat32\u001b[0m[1,16,16,64] │ \u001b[2mfloat32\u001b[0m[1,32,32,32] │ bias: \u001b[2mfloat32\u001b[0m[32]      │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[3,3,64,32]     │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m18,464 \u001b[0m\u001b[1;2m(73.9 KB)\u001b[0m       │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ decoder/Conv_0        │ Conv          │ \u001b[2mfloat32\u001b[0m[1,32,32,32] │ \u001b[2mfloat32\u001b[0m[1,32,32,1]  │ bias: \u001b[2mfloat32\u001b[0m[1]       │\n",
      "│                       │               │                     │                     │ kernel:                │\n",
      "│                       │               │                     │                     │ \u001b[2mfloat32\u001b[0m[3,3,32,1]      │\n",
      "│                       │               │                     │                     │                        │\n",
      "│                       │               │                     │                     │ \u001b[1m289 \u001b[0m\u001b[1;2m(1.2 KB)\u001b[0m           │\n",
      "├───────────────────────┼───────────────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m                     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m343,043 \u001b[0m\u001b[1;2m(1.4 MB)\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\n",
      "└───────────────────────┴───────────────┴─────────────────────┴─────────────────────┴────────────────────────┘\n",
      "\u001b[1m                                                                                                              \u001b[0m\n",
      "\u001b[1m                                      Total Parameters: 343,043 \u001b[0m\u001b[1;2m(1.4 MB)\u001b[0m\u001b[1m                                      \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AutoEncoder\n",
    "class AE(nn.Module):\n",
    "    latents: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(self.latents)\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        z = self.encoder(x)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x\n",
    "\n",
    "    def generate(self, z):\n",
    "        return nn.sigmoid(self.decoder(z))\n",
    "\n",
    "ae = AE(EMBEDDING_DIM)\n",
    "print(ae.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 32, 32, 1)), console_kwargs={'width': 110}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640a8d1-87d9-4a4a-b4fb-0557c2e99f99",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a802139-f45e-4460-a520-cfcb00b88283",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def binary_cross_entropy_with_logits(logits, label):\n",
    "    logits = nn.log_sigmoid(logits)\n",
    "    return -jnp.sum(labels * logits + (1. - labels) * jnp.log(-jnp.expm1(logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6645d-bd00-4207-b132-f893cce37a0e",
   "metadata": {},
   "source": [
    "## 3. Creating a `TrainState`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12fbd3c8-8657-4a9a-b625-3717b4a5a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(model, rng, learning_rate):\n",
    "    # Initialize the model\n",
    "    params = model.init(rng, jnp.ones([1, 32, 32, 1]))['params']\n",
    "    # Initialize the optimizer\n",
    "    tx = optax.adam(LEARNING_RATE)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=params,\n",
    "        tx=tx\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b8e5c-792b-49ff-a01b-7aa46119ffd3",
   "metadata": {},
   "source": [
    "## 4. Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "335a0beb-72cc-40db-9872-b649baaddf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch, z_rng):\n",
    "    def loss_fn(params):\n",
    "        recon_x = state.apply_fn({'params': params}, batch['image'])\n",
    "        loss = binary_cross_entropy_with_logits(recon_x, batch['image']).mean()\n",
    "        return loss\n",
    "    grad_fn = jax.grad(loss_fn)\n",
    "    grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5342511-0aad-4073-a39b-4d68af7af940",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_metrics(*, state, batch):\n",
    "    recon_x = state.apply_fn({'params': params}, batch['image'])\n",
    "    loss = binary_cross_entropy_with_logits(recon_x, batch['image']).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd370c9-5805-4353-982c-c44332da9387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
