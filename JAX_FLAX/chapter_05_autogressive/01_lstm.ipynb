{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e1ee6e-4367-4ef1-b15c-9ad225053267",
   "metadata": {},
   "source": [
    "# LSTM on Recipe Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8e0b4f-1228-4eda-8842-9bf19873b034",
   "metadata": {},
   "source": [
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/01_lstm/lstm.ipynb)\n",
    "- Dataset: [Kaggle](https://www.kaggle.com/datasets/hugodarwood/epirecipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d625ea0-486e-4619-ad9d-0ebbd7c24d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "\n",
    "from clu import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76dd9c-8a94-4b81-907d-b0a64ee0c905",
   "metadata": {},
   "source": [
    "## 0. Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4684fb-c1d3-41b8-b7da-4ea8da5dfa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/epirecipes/full_format_recipes.json'\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LSTM_LAYERS = 2\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "VOCAB_SIZE = 10000\n",
    "LR = 1e-3\n",
    "\n",
    "MAX_PAD_LEN = 200\n",
    "MAX_VAL_TOKENS = 100 # Max number of tokens when generating texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7785935-9cdb-4b7f-87d4-c62df452fa08",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c07bf4e-9e45-4811-a65c-b0e5378aeeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_punctuation(sentence):\n",
    "    sentence = re.sub(f'([{string.punctuation}])', r' \\1 ', sentence)\n",
    "    sentence = re.sub(' +', ' ', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad38cac-1ae6-42f7-95ef-3a9bff45e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "with open(DATA_DIR, 'r+') as f:\n",
    "    recipe_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f19bd7-9d03-4f72-8191-7d082c22663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total recipe loaded: 20098\n"
     ]
    }
   ],
   "source": [
    "# preprocess dataset\n",
    "filtered_data = [\n",
    "    'Recipe for ' + x['title'] + ' | ' + ' '.join(x['directions'])\n",
    "    for x in recipe_data\n",
    "    if 'title' in x and x['title']\n",
    "    and 'directions' in x and x['directions']\n",
    "]\n",
    "\n",
    "text_ds = [pad_punctuation(sentence) for sentence in filtered_data]\n",
    "print(f'Total recipe loaded: {len(text_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0bc4013-f1cb-46ea-81d1-abc8017365dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n",
      "Recipe for Beef , Mushroom , and Broccoli Stir - Fry | Cut steak with grain into 2 - inch - wide pieces , then slice thinly across grain . Combine 3 tablespoons water , 2 tablespoons vegetable oil , 2 tablespoons soy sauce , and 2 teaspoons cornstarch in large bowl . Add steak and stir to coat . Refrigerate at least 30 minutes . Combine 6 tablespoons broth , remaining 2 tablespoons soy sauce , and 6 teaspoons cornstarch , wine , and next 3 ingredients in small bowl , stirring to dissolve cornstarch completely . Heat 2 tablespoons vegetable oil in wok or heavy large skillet over high heat . Add steak with marinade and stir - fry until no longer pink , about 2 minutes . Transfer to platter . Add 2 tablespoons vegetable oil to wok . Add ginger and stir until aromatic , about 30 seconds . Add broccoli and stir - fry 1 minute . Add 1 cup broth . Cover , reduce heat and simmer 2 1 / 2 minutes . Transfer broccoli to bowl . Add 1 tablespoon vegetable oil to wok . Add mushrooms ; cook 2 minutes . Return steak and broccoli to wok . Stir sauce , add to wok and stir until sauce thickens , about 30 seconds . Transfer mixture to platter . Serve immediately with steamed rice . \n"
     ]
    }
   ],
   "source": [
    "print('Sample data:')\n",
    "sample_data = np.random.choice(text_ds)\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2809b15-a4bc-488c-a8cd-ae70f5fd1dae",
   "metadata": {},
   "source": [
    "## 2. Build vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8cf15a-6a3c-4b16-a7f5-06426b294859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver texts list to tf dataset\n",
    "text_ds_tf = Dataset.from_tensor_slices(text_ds)\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize='lower',\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_PAD_LEN+1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ccea64-db03-4e3b-b30c-6c2e4c88f92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: [UNK]\n",
      "2: .\n",
      "3: ,\n",
      "4: and\n",
      "5: to\n",
      "6: in\n",
      "7: the\n",
      "8: with\n",
      "9: a\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer.adapt(text_ds_tf)\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "index_to_word = {index : word for index, word in enumerate(vocab)}\n",
    "word_to_index = {word : index for index, word in enumerate(vocab)}\n",
    "\n",
    "# First 10 items in the vocabulary\n",
    "for i, word in enumerate(vocab[:10]):\n",
    "    print(f'{i}: {word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c385672-4086-4ddb-8113-e9efd56c2c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text:\n",
      "Recipe for Beef , Mushroom , and Broccoli Stir - Fry | Cut steak with grain into 2 - inch - wide pieces , then slice thinly across grain . Combine 3 tablespoons water , 2 tablespoons vegetable oil , 2 tablespoons soy sauce , and 2 teaspoons cornstarch in large bowl . Add steak and stir to coat . Refrigerate at least 30 minutes . Combine 6 tablespoons broth , remaining 2 tablespoons soy sauce , and 6 teaspoons cornstarch , wine , and next 3 ingredients in small bowl , stirring to dissolve cornstarch completely . Heat 2 tablespoons vegetable oil in wok or heavy large skillet over high heat . Add steak with marinade and stir - fry until no longer pink , about 2 minutes . Transfer to platter . Add 2 tablespoons vegetable oil to wok . Add ginger and stir until aromatic , about 30 seconds . Add broccoli and stir - fry 1 minute . Add 1 cup broth . Cover , reduce heat and simmer 2 1 / 2 minutes . Transfer broccoli to bowl . Add 1 tablespoon vegetable oil to wok . Add mushrooms ; cook 2 minutes . Return steak and broccoli to wok . Stir sauce , add to wok and stir until sauce thickens , about 30 seconds . Transfer mixture to platter . Serve immediately with steamed rice . \n",
      "\n",
      "\n",
      "Mapped sample:\n",
      "[  26   16  325    3  566    3    4  669   42   13  366   27   74  460\n",
      "    8 1090   25   15   13   53   13  527  220    3   46  284  651  807\n",
      " 1090    2  103   36   89   39    3   15   89  360   37    3   15   89\n",
      "  501   54    3    4   15  410  586    6   30   21    2   18  460    4\n",
      "   42    5  163    2  196   57  204  126   12    2  103  118   89  171\n",
      "    3   45   15   89  501   54    3    4  118  410  586    3  249    3\n",
      "    4  564   36  131    6   65   21    3   48    5  931  586  223    2\n",
      "   17   15   89  360   37    6  777   41   78   30   56   20   75   17\n",
      "    2   18  460    8  358    4   42   13  366   10  736  367  927    3\n",
      "   19   15   12    2   40    5  222    2   18   15   89  360   37    5\n",
      "  777    2   18  272    4   42   10 1747    3   19  126  295    2   18\n",
      "  669    4   42   13  366   11  164    2   18   11   52  171    2   49\n",
      "    3  153   17    4   70   15   11   23   15   12    2   40  669    5\n",
      "   21    2   18   11  133  360   37    5  777    2   18  275   22   43\n",
      "   15   12    2  246  460]\n"
     ]
    }
   ],
   "source": [
    "sample_data_tokenized = vectorize_layer(sample_data)\n",
    "print('Source text:')\n",
    "print(sample_data)\n",
    "print('\\n')\n",
    "print('Mapped sample:')\n",
    "print(sample_data_tokenized.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c4727-7bd6-49d3-a4b5-1ea3e37fd4bb",
   "metadata": {},
   "source": [
    "## 3. Create train/validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a717b2b3-68ce-4511-8c7a-6db64813f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map a single text slice into source and targets\n",
    "def map_src_tgt(text):\n",
    "    tokenized_sentence = vectorize_layer(text)\n",
    "    src = tokenized_sentence[:-1]\n",
    "    tgt = tokenized_sentence[1:]\n",
    "    return src, tgt\n",
    "    \n",
    "# create datasets\n",
    "def get_datasets(input_ds):\n",
    "    train_size = int(len(input_ds) * (1 - VALIDATION_SPLIT))\n",
    "    train_ds = input_ds.take(train_size) # take train dataset\n",
    "    valid_ds = input_ds.skip(train_size) # take validation dataset\n",
    "    print(f'train size: {train_ds.cardinality()}, valid size: {valid_ds.cardinality()}')\n",
    "\n",
    "    train_ds = train_ds.map(map_src_tgt)\n",
    "    valid_ds = valid_ds.map(map_src_tgt)\n",
    "    \n",
    "    train_ds = train_ds.batch(BATCH_SIZE).shuffle(1024).prefetch(1)\n",
    "    valid_ds = valid_ds.batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "    print(f'train batch: {train_ds.cardinality()}, valid batch: {valid_ds.cardinality()}')\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c14bc2df-97b5-404c-b600-e6481f16a187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 16078, valid size: 4020\n",
      "train batch: 503, valid batch: 126\n"
     ]
    }
   ],
   "source": [
    "train_ds, valid_ds = get_datasets(text_ds_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c4189-e96b-44d0-977e-c1eff2c61607",
   "metadata": {},
   "source": [
    "## 4. Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f616bd-e50c-4c44-ab5b-fcfcc686bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                              LSTM_model Summary                                              \u001b[0m\n",
      "┏━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│           │ LSTM_model │ \u001b[2mint32\u001b[0m[32,200]           │ \u001b[2mfloat32\u001b[0m[32,200,10000]   │                               │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ embed     │ Embed      │ \u001b[2mint32\u001b[0m[32,200]           │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ embedding: \u001b[2mfloat32\u001b[0m[10000,128] │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m1,280,000 \u001b[0m\u001b[1;2m(5.1 MB)\u001b[0m            │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0    │ LSTMCell   │ - - \u001b[2mfloat32\u001b[0m[32,200,128] │ - - \u001b[2mfloat32\u001b[0m[32,200,128] │                               │\n",
      "│           │            │   - \u001b[2mfloat32\u001b[0m[32,200,128] │   - \u001b[2mfloat32\u001b[0m[32,200,128] │                               │\n",
      "│           │            │ - \u001b[2mfloat32\u001b[0m[32,200,128]   │ - \u001b[2mfloat32\u001b[0m[32,200,128]   │                               │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0/ii │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,384 \u001b[0m\u001b[1;2m(65.5 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0/hi │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ bias: \u001b[2mfloat32\u001b[0m[128]            │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0/if │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,384 \u001b[0m\u001b[1;2m(65.5 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0/hf │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ bias: \u001b[2mfloat32\u001b[0m[128]            │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0/ig │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,384 \u001b[0m\u001b[1;2m(65.5 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0/hg │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ bias: \u001b[2mfloat32\u001b[0m[128]            │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0/io │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,384 \u001b[0m\u001b[1;2m(65.5 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_0/ho │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ bias: \u001b[2mfloat32\u001b[0m[128]            │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1    │ LSTMCell   │ - - \u001b[2mfloat32\u001b[0m[32,200,128] │ - - \u001b[2mfloat32\u001b[0m[32,200,128] │                               │\n",
      "│           │            │   - \u001b[2mfloat32\u001b[0m[32,200,128] │   - \u001b[2mfloat32\u001b[0m[32,200,128] │                               │\n",
      "│           │            │ - \u001b[2mfloat32\u001b[0m[32,200,128]   │ - \u001b[2mfloat32\u001b[0m[32,200,128]   │                               │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1/ii │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,384 \u001b[0m\u001b[1;2m(65.5 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1/hi │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ bias: \u001b[2mfloat32\u001b[0m[128]            │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1/if │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,384 \u001b[0m\u001b[1;2m(65.5 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1/hf │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ bias: \u001b[2mfloat32\u001b[0m[128]            │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1/ig │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,384 \u001b[0m\u001b[1;2m(65.5 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1/hg │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ bias: \u001b[2mfloat32\u001b[0m[128]            │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1/io │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,384 \u001b[0m\u001b[1;2m(65.5 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ lstm_1/ho │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ bias: \u001b[2mfloat32\u001b[0m[128]            │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,128]      │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m              │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│ dense     │ Dense      │ \u001b[2mfloat32\u001b[0m[32,200,128]     │ \u001b[2mfloat32\u001b[0m[32,200,10000]   │ bias: \u001b[2mfloat32\u001b[0m[10000]          │\n",
      "│           │            │                         │                         │ kernel: \u001b[2mfloat32\u001b[0m[128,10000]    │\n",
      "│           │            │                         │                         │                               │\n",
      "│           │            │                         │                         │ \u001b[1m1,290,000 \u001b[0m\u001b[1;2m(5.2 MB)\u001b[0m            │\n",
      "├───────────┼────────────┼─────────────────────────┼─────────────────────────┼───────────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                  Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m2,833,168 \u001b[0m\u001b[1;2m(11.3 MB)\u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\n",
      "└───────────┴────────────┴─────────────────────────┴─────────────────────────┴───────────────────────────────┘\n",
      "\u001b[1m                                                                                                              \u001b[0m\n",
      "\u001b[1m                                    Total Parameters: 2,833,168 \u001b[0m\u001b[1;2m(11.3 MB)\u001b[0m\u001b[1m                                     \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "\n",
    "    num_lstm_layers: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.embed = nn.Embed(num_embeddings=VOCAB_SIZE, features=HIDDEN_DIM)\n",
    "        self.lstm_layers = [nn.LSTMCell(name=f'lstm_{i}') for i in range(self.num_lstm_layers)]\n",
    "        self.dense = nn.Dense(features=VOCAB_SIZE)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Embedding\n",
    "        x = self.embed(x)\n",
    "\n",
    "        # LSTM\n",
    "        for i in range(self.num_lstm_layers):\n",
    "            hidden_state = self.lstm_layers[i].initialize_carry(jax.random.PRNGKey(0), (x.shape[0], x.shape[1]), HIDDEN_DIM)\n",
    "            _, x = self.lstm_layers[i](hidden_state, x)\n",
    "        \n",
    "        # Dense layer\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "lstm_model = LSTM_model(NUM_LSTM_LAYERS)\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "print(lstm_model.tabulate(rng, jnp.ones((BATCH_SIZE, MAX_PAD_LEN), dtype=int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c655caae-b24f-4b7d-aaf2-0f23e42fb42c",
   "metadata": {},
   "source": [
    "## 5. Create `TrainState`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad1c0d0f-8e64-4757-9c40-9e00a000f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    loss: metrics.Average.from_output('loss')\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "\n",
    "# train state for lstm model\n",
    "def create_train_state(model, param_key, learning_rate):\n",
    "    # initialize model\n",
    "    params = model.init(param_key, jnp.ones((BATCH_SIZE, MAX_PAD_LEN), dtype=int))['params']\n",
    "    # initialize optimizer\n",
    "    tx = optax.adam(learning_rate=learning_rate)\n",
    "    return TrainState.create(\n",
    "            apply_fn=model.apply,\n",
    "            params=params,\n",
    "            tx=tx,\n",
    "            metrics=Metrics.empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99e7e0-091a-43f8-88da-1c688debed12",
   "metadata": {},
   "source": [
    "## 6. Train step functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1249a94d-8cde-4c3b-8117-5c4d2dee48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        preds = state.apply_fn({'params': params}, batch[0])\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(preds, batch[1]).mean()\n",
    "        return loss\n",
    "\n",
    "    # compute loss and apply gradients\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "    # Update metrics\n",
    "    metric_updates = state.metrics.single_from_model_output(loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state \n",
    "\n",
    "\n",
    "# evaluation\n",
    "@jax.jit\n",
    "def validation(state, batch):\n",
    "    preds = state.apply_fn({'params': state.params}, batch[0])\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(preds, batch[1]).mean()\n",
    "\n",
    "    # Update metrics\n",
    "    metric_updates = state.metrics.single_from_model_output(loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72be04d9-b2b7-4e96-a67e-e278976f93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get next-word probability distribution\n",
    "@jax.jit\n",
    "def get_probs(state, input_tokens):\n",
    "    return state.apply_fn({'params': state.params}, input_tokens)[0][-1]\n",
    "\n",
    "\n",
    "# Text generator\n",
    "class TextGenerator():\n",
    "    def __init__(self, index_to_word):\n",
    "        self.index_to_word = index_to_word\n",
    "        self.word_to_index = {word : index for index, word in index_to_word.items()}\n",
    "\n",
    "    # scaling the model's output probability with temperature\n",
    "    def sample_from(self, probs, temperature):\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "        return np.random.choice(VOCAB_SIZE, p=probs), probs\n",
    "    \n",
    "    # generate text\n",
    "    def generate(self, state, start_prompt, max_tokens, temperature, output_info=False):\n",
    "        \n",
    "        start_tokens = [self.word_to_index[word] for word in start_prompt.split()]\n",
    "        sample_token = None\n",
    "        info = []\n",
    "\n",
    "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
    "            input_tokens = np.array(start_tokens).reshape(1, -1)\n",
    "            probs = get_probs(state, input_tokens)\n",
    "            probs = nn.log_softmax(probs)\n",
    "            sample_token, probs = self.sample_from(np.exp(probs), temperature)\n",
    "            start_tokens.append(sample_token)\n",
    "            if output_info:\n",
    "                info.append({'tokens': np.copy(start_tokens), 'word_probs': probs})\n",
    "            \n",
    "        output_text = [self.index_to_word[token] for token in start_tokens if token != 0]\n",
    "        print(' '.join(output_text))\n",
    "\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea137ad-33ca-4525-bbd5-ed3097b49214",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba8cf1f-9330-4a29-80b2-0c494b3327d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM_model(NUM_LSTM_LAYERS)\n",
    "state = create_train_state(lstm_model, jax.random.PRNGKey(0), learning_rate=LR)\n",
    "text_generator = TextGenerator(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99ebe744-3b35-4473-9e8a-35d81238c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-6916be85349e>:8: DeprecationWarning: ml_dtypes.float8_e4m3b11 is deprecated. Use ml_dtypes.float8_e4m3b11fnuz\n",
      "  state = train_step(state, batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tepoch time 0.09 min\n",
      "\ttrain loss: 4.4091, valid loss: 3.3011\n",
      "Epoch: 2\tepoch time 0.06 min\n",
      "\ttrain loss: 3.0457, valid loss: 2.8731\n",
      "Epoch: 3\tepoch time 0.06 min\n",
      "\ttrain loss: 2.8228, valid loss: 2.7695\n",
      "Epoch: 4\tepoch time 0.06 min\n",
      "\ttrain loss: 2.7429, valid loss: 2.7211\n",
      "Epoch: 5\tepoch time 0.06 min\n",
      "\ttrain loss: 2.6996, valid loss: 2.6936\n",
      "Epoch: 6\tepoch time 0.06 min\n",
      "\ttrain loss: 2.6717, valid loss: 2.6760\n",
      "Epoch: 7\tepoch time 0.06 min\n",
      "\ttrain loss: 2.6520, valid loss: 2.6626\n",
      "Epoch: 8\tepoch time 0.06 min\n",
      "\ttrain loss: 2.6370, valid loss: 2.6542\n",
      "Epoch: 9\tepoch time 0.06 min\n",
      "\ttrain loss: 2.6251, valid loss: 2.6465\n",
      "Epoch: 10\tepoch time 0.06 min\n",
      "\ttrain loss: 2.6155, valid loss: 2.6397\n",
      "\n",
      "Generated text:\n",
      "recipe for garbanzo and refrigerate overnight in middle of snap peas around residual heat until peppers , 20–30 minutes . crimp , if necessary . drop in a 25 minutes . drain well and simmer . meanwhile , pressing with the marinade ( tossing once , garlic , kale , just cooked through , about 15 minutes . put 1 1 / 4 cup patties to 30 minutes and pickle 10–12 minutes . starting with a time , leaving any air on 2 inches baking pan and sauce is al dente . )\n",
      "\n",
      "\n",
      "Epoch: 11\tepoch time 0.06 min\n",
      "\ttrain loss: 2.6073, valid loss: 2.6367\n",
      "Epoch: 12\tepoch time 0.06 min\n",
      "\ttrain loss: 2.6002, valid loss: 2.6319\n",
      "Epoch: 13\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5944, valid loss: 2.6297\n",
      "Epoch: 14\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5891, valid loss: 2.6268\n",
      "Epoch: 15\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5845, valid loss: 2.6252\n",
      "Epoch: 16\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5803, valid loss: 2.6223\n",
      "Epoch: 17\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5767, valid loss: 2.6207\n",
      "Epoch: 18\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5732, valid loss: 2.6193\n",
      "Epoch: 19\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5701, valid loss: 2.6193\n",
      "Epoch: 20\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5672, valid loss: 2.6172\n",
      "\n",
      "Generated text:\n",
      "recipe for spicy italian cream mixture ; sauté until smooth . assembly cooking liquid . whisk in a gas grill , then add milk and add half and bottom ) transfer the mixture over moderate heat to a platter , lemon peel . increase heat , 1 / 4 cup cooking the oven to a small saucepan and both sides with the bread . before it is very tender , again . ( taste and add the mixture may be made 1 / 4 . toss with oil in middle of water . continue cooking liquid water , halve each\n",
      "\n",
      "\n",
      "Epoch: 21\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5647, valid loss: 2.6174\n",
      "Epoch: 22\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5622, valid loss: 2.6158\n",
      "Epoch: 23\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5601, valid loss: 2.6148\n",
      "Epoch: 24\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5580, valid loss: 2.6151\n",
      "Epoch: 25\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5561, valid loss: 2.6134\n",
      "Epoch: 26\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5544, valid loss: 2.6135\n",
      "Epoch: 27\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5525, valid loss: 2.6124\n",
      "Epoch: 28\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5509, valid loss: 2.6122\n",
      "Epoch: 29\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5495, valid loss: 2.6117\n",
      "Epoch: 30\tepoch time 0.06 min\n",
      "\ttrain loss: 2.5479, valid loss: 2.6118\n",
      "\n",
      "Generated text:\n",
      "recipe for chicken breast meat pounder ( can be prepared dish . garnish . sift together milk , 1 teaspoon salt and the water to coat . mix until the mixture can be prepared 3 1 / 4 - inch ) . ( can be made 2 . working in a medium heat until the stalks , allowing clam juice over moderate heat . in 2 3 . drain spaghetti in a little at least 3 / 2 tablespoons dressing over medium , flattening phyllo on the onion . reduce heat and bones in butter and tomatoes , stirring occasionally\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_hist = defaultdict(list)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    prev_time = time.time()\n",
    "    \n",
    "    #training\n",
    "    for batch in train_ds.as_numpy_iterator():\n",
    "        state = train_step(state, batch)\n",
    "\n",
    "    train_loss = state.metrics.compute()['loss']\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    #validation\n",
    "    test_state = state\n",
    "    for batch in valid_ds.as_numpy_iterator():\n",
    "        test_state = validation(test_state, batch)\n",
    "\n",
    "    valid_loss = test_state.metrics.compute()['loss']\n",
    "    \n",
    "    loss_hist['train_loss'].append(train_loss)\n",
    "    loss_hist['valid_loss'].append(valid_loss)\n",
    "\n",
    "    curr_time = time.time()\n",
    "    print(f'Epoch: {i+1}\\tepoch time {(curr_time - prev_time) / 60:.2f} min')\n",
    "    print(f'\\ttrain loss: {train_loss:.4f}, valid loss: {valid_loss:.4f}')\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        # generate text\n",
    "        print('\\nGenerated text:')\n",
    "        info = text_generator.generate(state, 'recipe for', MAX_VAL_TOKENS, 1.0)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e8861-4971-423a-81ab-5f38512465ee",
   "metadata": {},
   "source": [
    "## 8. Generate texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06a2d4c7-c0d1-4972-9260-ac68b79e9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print prompt and top k candidate words probability\n",
    "def print_probs(info, index_to_word, top_k=5):\n",
    "    assert len(info) > 0, 'Please make `output_info=True`'\n",
    "    for i in range(len(info)):\n",
    "        start_tokens, word_probs = info[i].values()\n",
    "        start_prompts = [index_to_word[token] for token in start_tokens if token != 0]\n",
    "        start_prompts = ' '.join(start_prompts)\n",
    "        print(f'\\nPrompt: {start_prompts}')\n",
    "        # word_probs\n",
    "        probs_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
    "        for idx in probs_sorted:\n",
    "            print(f'{index_to_word[idx]}\\t{word_probs[idx] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b73be6f-b081-45c1-b998-73d9ceeec322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe for roast salmon . in\n",
      "\n",
      "Prompt: recipe for roast salmon\n",
      "until\t19.83%\n",
      ",\t8.73%\n",
      "in\t7.78%\n",
      "turkey\t7.03%\n",
      "chicken\t6.71%\n",
      "\n",
      "Prompt: recipe for roast salmon .\n",
      "with\t16.03%\n",
      ",\t10.33%\n",
      "and\t8.53%\n",
      ".\t7.59%\n",
      "fillets\t4.72%\n",
      "\n",
      "Prompt: recipe for roast salmon . in\n",
      "add\t10.62%\n",
      "\t5.22%\n",
      "transfer\t4.50%\n",
      "cover\t3.11%\n",
      "season\t2.77%\n"
     ]
    }
   ],
   "source": [
    "# Candidate words probability with temperature = 1.0\n",
    "info = text_generator.generate(state, \n",
    "                               'recipe for roast', \n",
    "                               max_tokens=6, \n",
    "                               temperature=1.0, \n",
    "                               output_info=True)\n",
    "\n",
    "print_probs(info, index_to_word, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2975f0c4-3c0e-4081-a365-83d9e83ec503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe for roast until just tender\n",
      "\n",
      "Prompt: recipe for roast until\n",
      "until\t96.50%\n",
      ",\t1.59%\n",
      "in\t0.90%\n",
      "turkey\t0.54%\n",
      "chicken\t0.43%\n",
      "\n",
      "Prompt: recipe for roast until just\n",
      "just\t35.86%\n",
      "smooth\t24.25%\n",
      "golden\t17.78%\n",
      "the\t15.51%\n",
      "mixture\t2.17%\n",
      "\n",
      "Prompt: recipe for roast until just tender\n",
      "tender\t68.73%\n",
      "until\t16.24%\n",
      "cooked\t14.73%\n",
      "to\t0.12%\n",
      "before\t0.12%\n"
     ]
    }
   ],
   "source": [
    "# Candidate words probability distribution with temperature = 1.0\n",
    "info = text_generator.generate(state, \n",
    "                               'recipe for roast', \n",
    "                               max_tokens=6, \n",
    "                               temperature=0.2, \n",
    "                               output_info=True)\n",
    "\n",
    "print_probs(info, index_to_word, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94def9a4-fc37-4154-877b-157f93039d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe for roast them into 1 / 4 - poached chicken with garlic , tilting and put in a serrated knife . cover and ginger in 3 minutes . pour into 2 tablespoons fat remaining sauce warm water to 2 / 4 cup parsley . sprinkle with rice , and bring cherries soften to small bowl . do not crisp - mushroom mixture is smooth paste forms . broil for grilled eggplant is heated through , eggs until nuts are browned , and pepper . remove from heat and chopped fresh or until beginning to tear the beans in same\n"
     ]
    }
   ],
   "source": [
    "# generate text with temperature = 1.0\n",
    "info = text_generator.generate(state, \n",
    "                               'recipe for roast', \n",
    "                               max_tokens=100, \n",
    "                               temperature=1.0, \n",
    "                               output_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4b2f17c-37e3-4990-a3b7-fa48cbe25f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe for roast until golden , and cook , about 5 minutes . add the mixture . add the mixture . add the garlic , about 5 minutes . add the mixture and cook , and pepper . transfer to a large bowl . add the mixture over medium heat , about 10 minutes . add the mixture to a large bowl . add the mixture to a large bowl . add the mixture , and refrigerate . add the mixture to a large bowl . add the mixture to a large bowl . add the bowl . add the\n"
     ]
    }
   ],
   "source": [
    "# generate text with temperature = 0.2\n",
    "info = text_generator.generate(state, \n",
    "                               'recipe for roast', \n",
    "                               max_tokens=100, \n",
    "                               temperature=0.2, \n",
    "                               output_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
