{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149f4744-522c-4514-ac6d-0a71f94920ce",
   "metadata": {},
   "source": [
    "# Energy-based Model (In-progress)\n",
    "\n",
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184?keywords=generative+deep+learning,+2nd+edition&qid=1684708209&sprefix=generative+de,aps,93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/07_ebm/01_ebm/ebm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced0082a-7774-49f8-95f9-637820666b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import random\n",
    "import collections\n",
    "from typing import Any\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from flax import struct\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax\n",
    "from clu import metrics\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb16883-163f-446e-bca6-3f45e997b83d",
   "metadata": {},
   "source": [
    "## 0. Training Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a8204c-1726-4682-8ba6-d91a170f8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "CHANNELS = 1\n",
    "STEP_SIZE = 10\n",
    "STEPS = 60\n",
    "NOISE = 5e-3\n",
    "ALPHA = 0.1\n",
    "GRADIENT_CLIP = 3e-2\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 8192\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 60\n",
    "\n",
    "# kwargs for model's tabulate function\n",
    "console_kwargs = {\"width\": 100, \n",
    "                  \"force_terminal\": False, \n",
    "                  \"force_jupyter\": True,\n",
    "                  \"soft_wrap\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea2d35-ae4f-4817-bc07-e198b607c86f",
   "metadata": {},
   "source": [
    "## 1. Preparing MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216cd17b-af5b-41d7-859e-b3aef1f39370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    imgs = (imgs.astype(\"float32\") - 127.5) / 127.5\n",
    "    imgs = np.pad(imgs, ((0, 0), (2, 2), (2, 2)), constant_values = -1.0)\n",
    "    imgs = np.expand_dims(imgs, axis=-1)\n",
    "    return imgs\n",
    "\n",
    "def get_dataset():\n",
    "    (train_ds, _), (test_ds, _) = datasets.mnist.load_data()\n",
    "    train_ds = preprocess(train_ds)\n",
    "    test_ds = preprocess(test_ds)\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(train_ds).shuffle(1024).batch(BATCH_SIZE)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(test_ds).batch(BATCH_SIZE)\n",
    "\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3dbcbf-b639-42ca-a0dc-5ce6bad04e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_ds, _ = get_dataset()\n",
    "sample_batch = next(sample_ds.as_numpy_iterator())\n",
    "print(sample_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e15d65-f22b-4fa1-bc5f-66fb8bfd9dce",
   "metadata": {},
   "source": [
    "## 2. Build Energy Function $E(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eafdb53-446d-4b65-88f4-dc13d18283fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Energy(nn.Module):\n",
    "\n",
    "    num_conv_layers:int = 4\n",
    "    # Flax module does not acceptable mutable properties\n",
    "    channels:tuple = tuple([16, 32, 64, 64])\n",
    "    kernels:tuple = tuple([5, 3, 3, 3])\n",
    "\n",
    "    def setup(self):\n",
    "        layers = []\n",
    "        for i in range(self.num_conv_layers):\n",
    "            layers.append(nn.Conv(features=self.channels[i],\n",
    "                                  kernel_size=(self.kernels[i], self.kernels[i]),\n",
    "                                  strides=2,\n",
    "                                  padding=\"same\"))\n",
    "            layers.append(nn.activation.swish)\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(layers)\n",
    "        self.liner_layers = nn.Sequential([nn.Dense(64),\n",
    "                                           nn.activation.swish,\n",
    "                                           nn.Dense(1)])\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        return self.liner_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54df992f-787a-420d-9de8-d0308917bf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                           Energy Summary                                           </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path                </span>┃<span style=\"font-weight: bold\"> module     </span>┃<span style=\"font-weight: bold\"> inputs             </span>┃<span style=\"font-weight: bold\"> outputs             </span>┃<span style=\"font-weight: bold\"> params             </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
       "│                     │ Energy     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32,32,1] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1]        │                    │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers         │ Sequential │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32,32,1] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,2,2,64]   │                    │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers/layers… │ Conv       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32,32,1] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,16,16,16] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[16]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[5,5,1,16]  │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ <span style=\"font-weight: bold\">416 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.7 KB)</span>       │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers/layers… │ Conv       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,16,16,1… │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,8,8,32]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[3,3,16,32] │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ <span style=\"font-weight: bold\">4,640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(18.6 KB)</span>    │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers/layers… │ Conv       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,8,8,32]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4,4,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[3,3,32,64] │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ <span style=\"font-weight: bold\">18,496 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(74.0 KB)</span>   │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers/layers… │ Conv       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4,4,64]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,2,2,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[3,3,64,64] │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ <span style=\"font-weight: bold\">36,928 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(147.7 KB)</span>  │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ liner_layers        │ Sequential │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,256]     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1]        │                    │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ liner_layers/layer… │ Dense      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,256]     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,64]       │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[256,64]    │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ <span style=\"font-weight: bold\">16,448 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(65.8 KB)</span>   │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ liner_layers/layer… │ Dense      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,64]      │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1]        │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]   │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,1]      │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ <span style=\"font-weight: bold\">65 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(260 B)</span>         │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│<span style=\"font-weight: bold\">                     </span>│<span style=\"font-weight: bold\">            </span>│<span style=\"font-weight: bold\">                    </span>│<span style=\"font-weight: bold\">               Total </span>│<span style=\"font-weight: bold\"> 76,993 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(308.0 KB)</span><span style=\"font-weight: bold\">  </span>│\n",
       "└─────────────────────┴────────────┴────────────────────┴─────────────────────┴────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                                    </span>\n",
       "<span style=\"font-weight: bold\">                                Total Parameters: 76,993 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(308.0 KB)</span><span style=\"font-weight: bold\">                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                           Energy Summary                                           \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams            \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
       "│                     │ Energy     │ \u001b[2mfloat32\u001b[0m[1,32,32,1] │ \u001b[2mfloat32\u001b[0m[1,1]        │                    │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers         │ Sequential │ \u001b[2mfloat32\u001b[0m[1,32,32,1] │ \u001b[2mfloat32\u001b[0m[1,2,2,64]   │                    │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers/layers… │ Conv       │ \u001b[2mfloat32\u001b[0m[1,32,32,1] │ \u001b[2mfloat32\u001b[0m[1,16,16,16] │ bias: \u001b[2mfloat32\u001b[0m[16]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ \u001b[2mfloat32\u001b[0m[5,5,1,16]  │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ \u001b[1m416 \u001b[0m\u001b[1;2m(1.7 KB)\u001b[0m       │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers/layers… │ Conv       │ \u001b[2mfloat32\u001b[0m[1,16,16,1… │ \u001b[2mfloat32\u001b[0m[1,8,8,32]   │ bias: \u001b[2mfloat32\u001b[0m[32]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ \u001b[2mfloat32\u001b[0m[3,3,16,32] │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ \u001b[1m4,640 \u001b[0m\u001b[1;2m(18.6 KB)\u001b[0m    │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers/layers… │ Conv       │ \u001b[2mfloat32\u001b[0m[1,8,8,32]  │ \u001b[2mfloat32\u001b[0m[1,4,4,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ \u001b[2mfloat32\u001b[0m[3,3,32,64] │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ \u001b[1m18,496 \u001b[0m\u001b[1;2m(74.0 KB)\u001b[0m   │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ conv_layers/layers… │ Conv       │ \u001b[2mfloat32\u001b[0m[1,4,4,64]  │ \u001b[2mfloat32\u001b[0m[1,2,2,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ \u001b[2mfloat32\u001b[0m[3,3,64,64] │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ \u001b[1m36,928 \u001b[0m\u001b[1;2m(147.7 KB)\u001b[0m  │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ liner_layers        │ Sequential │ \u001b[2mfloat32\u001b[0m[1,256]     │ \u001b[2mfloat32\u001b[0m[1,1]        │                    │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ liner_layers/layer… │ Dense      │ \u001b[2mfloat32\u001b[0m[1,256]     │ \u001b[2mfloat32\u001b[0m[1,64]       │ bias: \u001b[2mfloat32\u001b[0m[64]  │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ \u001b[2mfloat32\u001b[0m[256,64]    │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ \u001b[1m16,448 \u001b[0m\u001b[1;2m(65.8 KB)\u001b[0m   │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│ liner_layers/layer… │ Dense      │ \u001b[2mfloat32\u001b[0m[1,64]      │ \u001b[2mfloat32\u001b[0m[1,1]        │ bias: \u001b[2mfloat32\u001b[0m[1]   │\n",
       "│                     │            │                    │                     │ kernel:            │\n",
       "│                     │            │                    │                     │ \u001b[2mfloat32\u001b[0m[64,1]      │\n",
       "│                     │            │                    │                     │                    │\n",
       "│                     │            │                    │                     │ \u001b[1m65 \u001b[0m\u001b[1;2m(260 B)\u001b[0m         │\n",
       "├─────────────────────┼────────────┼────────────────────┼─────────────────────┼────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m76,993 \u001b[0m\u001b[1;2m(308.0 KB)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────────────┴────────────┴────────────────────┴─────────────────────┴────────────────────┘\n",
       "\u001b[1m                                                                                                    \u001b[0m\n",
       "\u001b[1m                                Total Parameters: 76,993 \u001b[0m\u001b[1;2m(308.0 KB)\u001b[0m\u001b[1m                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Energy().tabulate(jax.random.PRNGKey(0), jnp.ones((1, 32, 32, 1)), console_kwargs=console_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231af8ba-3bd9-4afc-a058-33236345d69d",
   "metadata": {},
   "source": [
    "## 3. Setting Up Langevin Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9437d4a3-01e9-4525-a0be-8d722df44e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(state, rng, input_imgs, steps, step_size, return_img_per_step=False):\n",
    "\n",
    "    @jax.grad\n",
    "    def grad_fn(input_imgs):\n",
    "        return state.apply_fn({\"params\": state.params},\n",
    "                              input_imgs).sum()\n",
    "\n",
    "    # for jit compiling purpose, we don't init the imgs_per_step array \n",
    "    # if not returning the generating sequence\n",
    "    if return_img_per_step:\n",
    "        imgs_per_step = []\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        # step 1, add noise to the input image\n",
    "        key, rng = jax.random.split(rng, 2)\n",
    "        noise = jax.random.normal(key, shape=input_imgs.shape)\n",
    "        input_imgs += noise\n",
    "        input_imgs = jnp.clip(input_imgs, a_min=-1.0, a_max=1.0)\n",
    "\n",
    "        # step 2, get gradients for the current input\n",
    "        grads = grad_fn(input_imgs)\n",
    "        grads = jnp.clip(grads, a_min=-GRADIENT_CLIP, a_max=GRADIENT_CLIP)\n",
    "\n",
    "        # step 3, apply gradients to the current input\n",
    "        input_imgs += grads\n",
    "        input_imgs = jnp.clip(input_imgs, a_min=-1.0, a_max=1.0)\n",
    "\n",
    "        if return_img_per_step:\n",
    "            imgs_per_step.append(np.array(input_imgs))\n",
    "\n",
    "    if return_img_per_step:\n",
    "        return np.stack(imgs_per_step, axis=0)\n",
    "    else:\n",
    "        return input_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e05563-fba4-4e57-9129-1f9cd0cbebd7",
   "metadata": {},
   "source": [
    "## 4. Setting up Buffer to Store Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "414edf45-54d8-4cfb-a1ce-cf5c2776b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "\n",
    "    sample_size:int = BATCH_SIZE\n",
    "    channels:int = CHANNELS\n",
    "    img_size:int = IMG_SIZE\n",
    "    buffer_size:int = BUFFER_SIZE\n",
    "    rng:Any = jax.random.PRNGKey(0)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.examples = []\n",
    "        for _ in range(self.sample_size):\n",
    "            self.examples.append(\n",
    "                np.random.uniform(low=-1.0, high=1.0, size=(1, self.img_size, self.img_size, self.channels))\n",
    "            )\n",
    "        self.generate_samples = jax.jit(generate_samples, static_argnums=(3, 4, 5))\n",
    "\n",
    "    def sample_new_exmps(self, state, steps, step_size):\n",
    "        n_new = np.random.binomial(self.sample_size, 0.05)\n",
    "        rand_imgs = np.random.uniform(low=-1.0, \n",
    "                                      high=1.0, \n",
    "                                      size=(n_new, self.img_size, self.img_size, self.channels))\n",
    "        old_imgs = np.concatenate(random.choices(self.examples, k=self.sample_size-n_new), axis=0)\n",
    "        input_imgs = np.concatenate([rand_imgs, old_imgs], axis=0)\n",
    "\n",
    "        input_imgs = self.generate_samples(state, self.rng, input_imgs, steps, step_size)\n",
    "        input_imgs = np.array(input_imgs)\n",
    "        self.examples = np.split(input_imgs, \n",
    "                                 indices_or_sections=self.sample_size,\n",
    "                                 axis=0) + self.examples\n",
    "        self.examples = self.examples[:self.buffer_size]\n",
    "        return input_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9ee06-de2e-4140-9ad6-aef14e33b8e5",
   "metadata": {},
   "source": [
    "## 5. Setting up EBM `TrainState`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef2e9705-c063-4439-b79e-4a165f8e1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class TrainMetrics(metrics.Collection):\n",
    "    loss: metrics.Average.from_output(\"loss\")\n",
    "    cdiv_loss: metrics.Average.from_output(\"cdiv_loss\")\n",
    "    reg_loss: metrics.Average.from_output(\"reg_loss\")\n",
    "    real: metrics.Average.from_output(\"real\")\n",
    "    fake: metrics.Average.from_output(\"fake\")\n",
    "\n",
    "@struct.dataclass\n",
    "class ValidMetrics(metrics.Collection):\n",
    "    cdiv_loss: metrics.Average.from_output(\"cdiv_loss\")\n",
    "    real: metrics.Average.from_output(\"real\")\n",
    "    fake: metrics.Average.from_output(\"fake\")\n",
    "\n",
    "\n",
    "# EBM state class inherits flax's TrainState class\n",
    "class EBM_state(train_state.TrainState):\n",
    "    train_metrics: TrainMetrics\n",
    "    valid_metrics: ValidMetrics\n",
    "\n",
    "\n",
    "def create_ebm_state(model, params_key, lr=LEARNING_RATE):\n",
    "\n",
    "    params = model.init(params_key, jnp.ones((1, IMG_SIZE, IMG_SIZE, CHANNELS)))[\"params\"]\n",
    "    tx = optax.adam(learning_rate=lr)\n",
    "\n",
    "    return EBM_state.create(\n",
    "                apply_fn = model.apply,\n",
    "                params=params,\n",
    "                tx=tx,\n",
    "                train_metrics=TrainMetrics.empty(),\n",
    "                valid_metrics=ValidMetrics.empty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87900c1b-1741-4fc8-8785-0f85861d8041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EBM:\n",
    "\n",
    "#     alpha:float = ALPHA\n",
    "#     lr:float = LEARNING_RATE\n",
    "#     steps:int = STEPS\n",
    "#     step_size:float = STEP_SIZE\n",
    "#     noise_scale:float = NOISE\n",
    "\n",
    "#     def __init__(self, model):\n",
    "#         self.rng = jax.random.PRNGKey(0)\n",
    "#         self.state = create_ebm_state(model, rng, self.lr)\n",
    "#         self.buffer = Buffer()\n",
    "\n",
    "    \n",
    "#     def train(self, real_imgs):    \n",
    "#         key, self.rng = jax.random.split(self.rng, 2)\n",
    "#         noise = jax.random.normal(key, shape=real_imgs.shape) * self.noise_scale\n",
    "#         real_imgs += noise\n",
    "#         real_imgs = jnp.clip(real_imgs, a_min=-1.0, a_max=1.0)\n",
    "#         fake_imgs = self.buffer.sample_new_exmps(self.state, self.steps, self.step_size)\n",
    "#         input_imgs = jnp.concatenate([real_imgs, fake_imgs], axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6590c06d-0b2c-4a97-86bd-6c8ee0227612",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def emb_forward(state, input_imgs):\n",
    "    # loss function\n",
    "    def loss_fn(params, state):\n",
    "        output = state.apply_fn({\"params\":params}, input_imgs)\n",
    "        real_out, fake_out = jnp.split(output, indices_or_sections=2)\n",
    "\n",
    "        reg_loss = ALPHA * (real_out ** 2 + fake_out ** 2).mean()\n",
    "        cdiv_loss = fake_out.mean() - real_out.mean()\n",
    "        loss = reg_loss + cdiv_loss\n",
    "\n",
    "        metrics_updates = state.train_metrics.single_from_model_output(\n",
    "                                reg_loss = reg_loss,\n",
    "                                cdiv_loss = cdiv_loss,\n",
    "                                loss = loss,\n",
    "                                real = real_out.mean(),\n",
    "                                fake = fake_out.mean())\n",
    "\n",
    "        train_metrics = state.train_metrics.merge(metrics_updates)\n",
    "        state = state.replace(train_metrics = train_metrics)\n",
    "        return loss, state\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, state), grads = grad_fn(state.params, state)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state\n",
    "\n",
    "\n",
    "def train_step():\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdae7920-7e92-481b-93fd-fd3dadf333e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_model = Energy()\n",
    "# ebm = EBM(energy_model)\n",
    "buffer = Buffer()\n",
    "rng = jax.random.PRNGKey(0)\n",
    "ebm_state = create_ebm_state(energy_model, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dde84cc-0b5d-457f-b890-8371003dd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = emb_forward(ebm_state, sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14386c16-a48a-4a3e-8653-edfa3dd1d7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
