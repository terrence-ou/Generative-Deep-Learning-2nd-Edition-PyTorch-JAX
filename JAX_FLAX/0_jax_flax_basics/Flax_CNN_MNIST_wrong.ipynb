{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecfc63a3-9916-4e94-b3eb-48a634dfdfce",
   "metadata": {},
   "source": [
    "# Train MNIST dataset with PyTorch Data Loading and flax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d54d5-1ed8-4d08-9607-169c1c267a31",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9bcaf2c-256e-4310-9628-a84be1a4ad4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from jax import numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94625779-c030-4f99-9938-5a41e2ed5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple, list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "class NumpyLoader(data.DataLoader):\n",
    "  def __init__(self, dataset, batch_size=1,\n",
    "                shuffle=False, sampler=None,\n",
    "                batch_sampler=None, num_workers=0,\n",
    "                pin_memory=False, drop_last=False,\n",
    "                timeout=0, worker_init_fn=None):\n",
    "    super(self.__class__, self).__init__(dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        sampler=sampler,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=numpy_collate,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        timeout=timeout,\n",
    "        worker_init_fn=worker_init_fn)\n",
    "\n",
    "class FlattenAndCast(object):\n",
    "  def __call__(self, pic):\n",
    "    return np.expand_dims(np.array(pic, dtype=jnp.float32), axis=-1) / 255.0\n",
    "    # return np.array(pic, dtype=jnp.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e88d6b9-7e56-4d6d-8f32-ce8ccbe883fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Define dataset\n",
    "mnist_dataset = MNIST(root='./data', download=True, transform=FlattenAndCast())\n",
    "mnist_dataset_test = MNIST(root='./data', download=True, train=False, transform=FlattenAndCast())\n",
    "\n",
    "# train_images = jnp.array(mnist_dataset.data) / 255.0\n",
    "# train_labels = jnp.array(mnist_dataset.targets)\n",
    "\n",
    "# test_images = jnp.array(mnist_dataset_test.data) / 255.0\n",
    "# test_labels = jnp.array(mnist_dataset_test.targets)\n",
    "\n",
    "train_loader = NumpyLoader(dataset=mnist_dataset, \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0)\n",
    "test_loader = NumpyLoader(dataset=mnist_dataset_test,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b85f9752-e8ec-4cc7-9886-db79cf22ea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "test=next(iter(test_loader))\n",
    "img = test[0][0]\n",
    "print(test[1][0])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d12549-3699-403b-9530-b10ae9c2cfba",
   "metadata": {},
   "source": [
    "## 2. Define a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62b5ba71-9cbb-49c3-89b0-fdde689e335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn # Linen API\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1)) # flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b66559-bcb0-43cc-b3fb-aeb96eabda5e",
   "metadata": {},
   "source": [
    "## 3. View Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d4ee06a-2453-49a1-b550-263e017b745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                  CNN Summary                                   \u001b[0m\n",
      "┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams           \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
      "│         │ CNN    │ \u001b[2mfloat32\u001b[0m[1,28,28,… │ \u001b[2mfloat32\u001b[0m[1,10]     │                   │\n",
      "├─────────┼────────┼───────────────────┼───────────────────┼───────────────────┤\n",
      "│ Conv_0  │ Conv   │ \u001b[2mfloat32\u001b[0m[1,28,28,… │ \u001b[2mfloat32\u001b[0m[1,28,28,… │ bias: \u001b[2mfloat32\u001b[0m[32] │\n",
      "│         │        │                   │                   │ kernel:           │\n",
      "│         │        │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,1,32] │\n",
      "│         │        │                   │                   │                   │\n",
      "│         │        │                   │                   │ \u001b[1m320 \u001b[0m\u001b[1;2m(1.3 KB)\u001b[0m      │\n",
      "├─────────┼────────┼───────────────────┼───────────────────┼───────────────────┤\n",
      "│ Conv_1  │ Conv   │ \u001b[2mfloat32\u001b[0m[1,14,14,… │ \u001b[2mfloat32\u001b[0m[1,14,14,… │ bias: \u001b[2mfloat32\u001b[0m[64] │\n",
      "│         │        │                   │                   │ kernel:           │\n",
      "│         │        │                   │                   │ \u001b[2mfloat32\u001b[0m[3,3,32,6… │\n",
      "│         │        │                   │                   │                   │\n",
      "│         │        │                   │                   │ \u001b[1m18,496 \u001b[0m\u001b[1;2m(74.0 KB)\u001b[0m  │\n",
      "├─────────┼────────┼───────────────────┼───────────────────┼───────────────────┤\n",
      "│ Dense_0 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,3136]   │ \u001b[2mfloat32\u001b[0m[1,256]    │ bias:             │\n",
      "│         │        │                   │                   │ \u001b[2mfloat32\u001b[0m[256]      │\n",
      "│         │        │                   │                   │ kernel:           │\n",
      "│         │        │                   │                   │ \u001b[2mfloat32\u001b[0m[3136,256] │\n",
      "│         │        │                   │                   │                   │\n",
      "│         │        │                   │                   │ \u001b[1m803,072 \u001b[0m\u001b[1;2m(3.2 MB)\u001b[0m  │\n",
      "├─────────┼────────┼───────────────────┼───────────────────┼───────────────────┤\n",
      "│ Dense_1 │ Dense  │ \u001b[2mfloat32\u001b[0m[1,256]    │ \u001b[2mfloat32\u001b[0m[1,10]     │ bias: \u001b[2mfloat32\u001b[0m[10] │\n",
      "│         │        │                   │                   │ kernel:           │\n",
      "│         │        │                   │                   │ \u001b[2mfloat32\u001b[0m[256,10]   │\n",
      "│         │        │                   │                   │                   │\n",
      "│         │        │                   │                   │ \u001b[1m2,570 \u001b[0m\u001b[1;2m(10.3 KB)\u001b[0m   │\n",
      "├─────────┼────────┼───────────────────┼───────────────────┼───────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m824,458 \u001b[0m\u001b[1;2m(3.3 MB)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\n",
      "└─────────┴────────┴───────────────────┴───────────────────┴───────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                       Total Parameters: 824,458 \u001b[0m\u001b[1;2m(3.3 MB)\u001b[0m\u001b[1m                       \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 28, 28, 1)))) # (batch, h, w, channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ec999-777c-42ac-8f54-50a05a8f157f",
   "metadata": {},
   "source": [
    "## 4. Create a `TrainState`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd8dcfc-9207-4f0f-b9e8-6f9d6c7e9b35",
   "metadata": {},
   "source": [
    "A common pattern in Flax is to create a single dataclass that represents the entire training state, including step number, parameters, and optimizer state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5696a40-cffa-40d0-9e24-0e0dacda35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clu import metrics\n",
    "from flax.training import train_state # Useful dataclass to keep train state\n",
    "from flax import struct               # Flas dataclass\n",
    "import optax                          # Common loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57c618df-e2e4-48f0-bb8c-01c7815d3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    accuracy: metrics.Accuracy\n",
    "    loss: metrics.Average.from_output('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c0ae24f-2196-413d-85c0-aa6e829f27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "\n",
    "def create_train_state(module, rng, learning_rate, momentum):\n",
    "    params = module.init(rng, jnp.ones([1, 28, 28, 1]))['params'] # initializing parameters by passing a template image\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return TrainState.create(\n",
    "            apply_fn=module.apply,\n",
    "            params=params,\n",
    "            tx=tx,\n",
    "            metrics=Metrics.empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb41de-d4b9-4c78-86ec-adbb47f0c3c2",
   "metadata": {},
   "source": [
    "## 5. Training step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72b63d-087c-48e5-8801-badfb6405f77",
   "metadata": {},
   "source": [
    "A function that:\n",
    "- Evaluates the neural network given the parameters and a batch of input images with `TrainState.apply_fn`;\n",
    "- Computes the cross entropy loss, using the predefined `optax.softmax_cross_entropy_with_integer_labels()`. Note that this function expects integer labels, so there is no need to convert labels to onehot encoding.\n",
    "- Evaluates the gradient of the loss function using `jax.grad`.\n",
    "- Applies a pytree of gradients to the optimizer to update the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25d0cb97-9f48-4b35-9df3-aa58b02ab591",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, images, targets):\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, images)\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=targets).mean()\n",
    "        return loss\n",
    "    grad_fn = jax.grad(loss_fn)\n",
    "    grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32439cdc-a9a8-4dfe-8983-a2a0b8905cb5",
   "metadata": {},
   "source": [
    "## 6. Metric computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed1cfecc-31a6-4ba2-9109-5ee2d18466d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_metrics(*, state, images, targets):\n",
    "    logits = state.apply_fn({'params': state.params}, images)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=targets).mean()\n",
    "    metric_updates = state.metrics.single_from_model_output(\n",
    "        logits=logits, labels=targets, loss=loss\n",
    "    )\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75827ecb-6d87-4291-8725-f1739e9b2266",
   "metadata": {},
   "source": [
    "## 7. Set Seed and train params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4dbb101-4f92-4526-9270-7360e1987fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "torch.manual_seed(0)\n",
    "init_rng = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b4255-c0c6-4c66-9b90-98842da44d07",
   "metadata": {},
   "source": [
    "## 8. Initialize the `TrainState`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b02f948-fa64-4ba5-a34d-de6b9f84084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(cnn, init_rng, learning_rate, momentum)\n",
    "del init_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834cc95f-f4c6-4cf8-9ceb-805767da3e8d",
   "metadata": {},
   "source": [
    "## 9. Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc90b62c-0824-4b25-947e-73869cb609f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps_per_epoch = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51ca607c-6f06-4eec-bdb9-4cd85fcb6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'test_loss': [],\n",
    "    'test_accuracy': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6209845-7b04-4df0-a186-9309c6438013",
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_epoch in range(num_epochs):\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        # Run optimization steps over training batches and compute batch metrics\n",
    "        state = train_step(state, images, targets)\n",
    "        state = compute_metrics(state=state, images=images, targets=targets)\n",
    "    \n",
    "    for metric, value in state.metrics.compute().items():\n",
    "        metrics_history[f'train_{metric}'].append(value)\n",
    "        \n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    # test_state = state\n",
    "    # for images, targets in enumerate(test_loader):\n",
    "    #     test_state = compute_metrics(state=test_state, images=images, targets=targets)\n",
    "\n",
    "    # for metric, value in test_state.metrics.compute().items():\n",
    "    #     metrics_history[f'test_{metric}'].append(value)\n",
    "\n",
    "    print(f'Epoch: {curr_epoch + 1}:')\n",
    "    print(f'\\tTrain Metrics: Loss={metrics_history[\"train_loss\"][-1]:.4f}, Accuracy={metrics_history[\"train_accuracy\"][-1]*100:.4f}')\n",
    "    # print(f'\\tTest Metrics: Loss={metrics_history[\"test_loss\"][-1]:.4f}, Accuracy={metrics_history[\"test_accuracy\"][-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c451329-dc1c-49ec-b13f-fec0706ee15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
