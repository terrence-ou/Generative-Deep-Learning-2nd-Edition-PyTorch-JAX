{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb77744-578c-4b3e-9507-104e361021cb",
   "metadata": {},
   "source": [
    "# PixelCNN for FashionMNIST\n",
    "\n",
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/02_pixelcnn/pixelcnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb0648c9-19ba-4f25-b5a8-73e36dcb4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import struct\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax\n",
    "\n",
    "from clu import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec6a3f-fdfd-4f37-825b-aac09f03e764",
   "metadata": {},
   "source": [
    "## 0. Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b4db859-14a6-4ca3-a9c8-256976003447",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "CHANNELS = 1\n",
    "PIXEL_LEVELS = 8\n",
    "N_FILTERS = 128\n",
    "RESIDUAL_BLOCKS = 5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LR = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce902e-fd78-403a-b4a3-7a90e49e255d",
   "metadata": {},
   "source": [
    "## 1. Preparing FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a84e3f0-154b-4ff7-a0d5-3917d9546e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn input image into pixels and per-pixel labels\n",
    "def preprocess(imgs):\n",
    "    imgs = imgs['image']\n",
    "    imgs_int = tf.image.resize(imgs, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    imgs_int = tf.cast((imgs_int / (256 / PIXEL_LEVELS)), tf.int32)\n",
    "    imgs = tf.cast(imgs_int, tf.float32)\n",
    "    imgs = imgs / PIXEL_LEVELS\n",
    "    return {'image': imgs, 'label': imgs_int}\n",
    "\n",
    "# Get train/valid datasets\n",
    "def get_datasets():\n",
    "    train_ds, valid_ds = tfds.load('fashion_mnist', split=['train', 'test'])\n",
    "    \n",
    "    train_ds = train_ds.map(lambda sample: preprocess(sample))\n",
    "    valid_ds = valid_ds.map(lambda sample: preprocess(sample))\n",
    "    \n",
    "    train_ds = train_ds.shuffle(1024).batch(BATCH_SIZE).prefetch(1)\n",
    "    valid_ds = valid_ds.batch(BATCH_SIZE).prefetch(1)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04587b13-e9ea-41aa-9b96-c335a2366628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check dataset\n",
    "def plot_imgs(batch, num_rows=2, num_cols=6):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i in range(num_cols * num_rows):\n",
    "        ax = plt.subplot(num_rows, num_cols, i + 1)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(batch[i], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "test_ds, _ = get_datasets()\n",
    "test_batch = next(test_ds.as_numpy_iterator())['image']\n",
    "plot_imgs(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43311f-62e7-48d6-b1df-d7be3e936b98",
   "metadata": {},
   "source": [
    "## 2. Build the PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc01f21-ec8a-425a-be9d-de3978047674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(nn.Module):\n",
    "    in_features: int # The number of input features\n",
    "    out_features: int # The number of output features\n",
    "    kernel_size: tuple\n",
    "    mask_type: str\n",
    "    padding: str\n",
    "\n",
    "    def setup(self):\n",
    "        assert self.mask_type in ['A', 'B'], 'Mask type should be either A or B'\n",
    "        kh, kw = self.kernel_size\n",
    "\n",
    "        # Generating mask -> shape (k, k)\n",
    "        mask = jnp.ones(shape=self.kernel_size)\n",
    "        mask = mask.at[kh // 2 + 1:,].set(0)\n",
    "        mask = mask.at[kh // 2, kw // 2 + 1:].set(0)\n",
    "\n",
    "        if self.mask_type == 'A':\n",
    "            mask = mask.at[kh // 2, kw // 2].set(0)\n",
    "            \n",
    "        # Expanding and repeating the mask -> shape (k, k, in_features, out_features)\n",
    "        mask = mask[:, :, None, None]\n",
    "        mask = jnp.tile(mask, (1, 1, self.in_features, self.out_features))\n",
    "        \n",
    "        self.conv = nn.Conv(features=self.out_features, \n",
    "                            kernel_size=self.kernel_size, \n",
    "                            padding=self.padding, \n",
    "                            mask=mask)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47c941b4-d36b-4c00-876f-611d6af1cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check masked conv\n",
    "# masked_conv = MaskedConv2D(1, 128, (7, 7), 'A', 'same')\n",
    "# print(masked_conv.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 16, 16, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "894abf2f-f176-454c-adb1-f180dfc8eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    features:int\n",
    "    \n",
    "    def setup(self):\n",
    "\n",
    "        self.conv_1 = nn.Sequential([\n",
    "                        nn.Conv(features=self.features // 2, \n",
    "                              kernel_size=(1, 1),\n",
    "                              strides=1),\n",
    "                        nn.relu])\n",
    "        \n",
    "        self.pixel_conv = nn.Sequential([\n",
    "                            MaskedConv2D(in_features=self.features // 2,\n",
    "                                       out_features=self.features // 2,\n",
    "                                       kernel_size=(3, 3),\n",
    "                                       mask_type='B',\n",
    "                                       padding='same'),\n",
    "                            nn.relu])\n",
    "\n",
    "        self.conv_2 = nn.Sequential([\n",
    "                        nn.Conv(features=self.features,\n",
    "                              kernel_size=(1, 1),\n",
    "                              strides=1),\n",
    "                        nn.relu])\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        conv_x = self.conv_1(x)\n",
    "        conv_x = self.pixel_conv(conv_x)\n",
    "        conv_x = self.conv_2(conv_x)\n",
    "        return conv_x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14e142d2-4796-45c7-9495-27903cf1c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check residual block\n",
    "# res_block = ResidualBlock(128) \n",
    "# print(res_block.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 16, 16, 128))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a364236-2389-4f93-92d9-a1f967a04b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "\n",
    "    in_channels:int\n",
    "    num_filters:int\n",
    "    num_res_blocks:int\n",
    "    output_size:int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.masked_conv_1 = nn.Sequential([\n",
    "                                MaskedConv2D(in_features=self.in_channels, \n",
    "                                             out_features=self.num_filters,\n",
    "                                             kernel_size=(7, 7),\n",
    "                                             mask_type='A',\n",
    "                                             padding='same'),\n",
    "                                nn.relu])\n",
    "\n",
    "        self.res_blocks = nn.Sequential([\n",
    "                                ResidualBlock(self.num_filters) \n",
    "                                    for _ in range(self.num_res_blocks)])\n",
    "\n",
    "        masked_conv_2_layers = []\n",
    "        for _ in range(2):\n",
    "            masked_conv_2_layers.append(MaskedConv2D(in_features=self.num_filters,\n",
    "                                                out_features=self.num_filters,\n",
    "                                                kernel_size=(1, 1),\n",
    "                                                mask_type='B',\n",
    "                                                padding='valid'))\n",
    "            masked_conv_2_layers.append(nn.relu)\n",
    "\n",
    "        self.masked_conv_2 = nn.Sequential(masked_conv_2_layers)\n",
    "\n",
    "        self.output_conv = nn.Conv(features=self.output_size,\n",
    "                                   kernel_size=(1, 1),\n",
    "                                   padding='valid')\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.masked_conv_1(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.masked_conv_2(x)\n",
    "        x = self.output_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e005b975-d25a-4a37-9074-39f654a8c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                                  PixelCNN Summary                                                   \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                    \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│                        │ PixelCNN      │ \u001b[2mfloat32\u001b[0m[1,16,16,1]   │ \u001b[2mfloat32\u001b[0m[1,16,16,8]   │                            │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ masked_conv_1          │ Sequential    │ \u001b[2mfloat32\u001b[0m[1,16,16,1]   │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │                            │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ masked_conv_1/layers_0 │ MaskedConv2D  │ \u001b[2mfloat32\u001b[0m[1,16,16,1]   │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m6,400 \u001b[0m\u001b[1;2m(25.6 KB)\u001b[0m            │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ res_blocks             │ Sequential    │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │                            │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ res_blocks/layers_0    │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m          │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ res_blocks/layers_1    │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m          │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ res_blocks/layers_2    │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m          │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ res_blocks/layers_3    │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m          │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ res_blocks/layers_4    │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m          │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ masked_conv_2          │ Sequential    │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │                            │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ masked_conv_2/layers_0 │ MaskedConv2D  │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m           │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ masked_conv_2/layers_2 │ MaskedConv2D  │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m           │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ output_conv            │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,8]   │ bias: \u001b[2mfloat32\u001b[0m[8]           │\n",
      "│                        │               │                      │                      │ kernel: \u001b[2mfloat32\u001b[0m[1,1,128,8] │\n",
      "│                        │               │                      │                      │                            │\n",
      "│                        │               │                      │                      │ \u001b[1m1,032 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
      "├────────────────────────┼───────────────┼──────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m                      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m307,976 \u001b[0m\u001b[1;2m(1.2 MB)\u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\n",
      "└────────────────────────┴───────────────┴──────────────────────┴──────────────────────┴────────────────────────────┘\n",
      "\u001b[1m                                                                                                                     \u001b[0m\n",
      "\u001b[1m                                         Total Parameters: 307,976 \u001b[0m\u001b[1;2m(1.2 MB)\u001b[0m\u001b[1m                                          \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check PixelCNN model\n",
    "pixel_cnn = PixelCNN(CHANNELS, N_FILTERS, RESIDUAL_BLOCKS, PIXEL_LEVELS)\n",
    "print(pixel_cnn.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 16, 16, 1)), depth=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4a90a-8878-4272-9eec-b936ed47aee2",
   "metadata": {},
   "source": [
    "## 3. Functions for `Train State`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f52cf99e-ea5e-49be-8a1f-5f46c83c2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    loss = metrics.Average.from_output('loss')\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "\n",
    "def create_train_state(model, param_key, learning_rate):\n",
    "    # initialize model parameters\n",
    "    params = model.init(param_key, jnp.ones((BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)))['params']\n",
    "    # initialize optimizer\n",
    "    tx = optax.adam(learning_rate=LR)\n",
    "    return TrainState.create(\n",
    "                apply_fn=model.apply,\n",
    "                params=params,\n",
    "                tx=tx,\n",
    "                metrics=Metrics.empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0074c1-7db9-45a4-b110-d13a69b5a34a",
   "metadata": {},
   "source": [
    "## 4. Train step functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ebe7920-3c9f-45f2-9340-2a88d343ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        preds = state.apply_fn({'params': params}, batch['image'])\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(preds, batch['label']).mean()\n",
    "        return loss\n",
    "\n",
    "    # compute loss and apply gradients\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    # update metrics\n",
    "    metric_updates = state.metircs.single_from_model_output(loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "\n",
    "# Validation\n",
    "@jax.jit\n",
    "def validation(state, batch):\n",
    "    preds = state.apply_fn({'params': state.params}, batch['image'])\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(preds, batch['label']).mean()\n",
    "\n",
    "    # update metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612efd7c-93e6-4c34-8daa-223544be5b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
