{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb77744-578c-4b3e-9507-104e361021cb",
   "metadata": {},
   "source": [
    "# PixelCNN for FashionMNIST\n",
    "\n",
    "**In progress**\n",
    "\n",
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/02_pixelcnn/pixelcnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0648c9-19ba-4f25-b5a8-73e36dcb4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import struct\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax\n",
    "from clu import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec6a3f-fdfd-4f37-825b-aac09f03e764",
   "metadata": {},
   "source": [
    "## 0. Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4db859-14a6-4ca3-a9c8-256976003447",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "CHANNELS = 1\n",
    "PIXEL_LEVELS = 8\n",
    "N_FILTERS = 128\n",
    "RESIDUAL_BLOCKS = 5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce902e-fd78-403a-b4a3-7a90e49e255d",
   "metadata": {},
   "source": [
    "## 1. Preparing FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a84e3f0-154b-4ff7-a0d5-3917d9546e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn input image into pixels and per-pixel labels\n",
    "def preprocess(imgs):\n",
    "    imgs = imgs['image']\n",
    "    imgs_int = tf.image.resize(imgs, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    imgs_int = tf.cast((imgs_int / (256 / PIXEL_LEVELS)), tf.int32)\n",
    "    imgs = tf.cast(imgs_int, tf.float32)\n",
    "    imgs = imgs / PIXEL_LEVELS\n",
    "    return {'image': imgs, 'label': imgs_int}\n",
    "\n",
    "# Get train/valid datasets\n",
    "def get_datasets():\n",
    "    train_ds, valid_ds = tfds.load('fashion_mnist', split=['train', 'test'])\n",
    "    \n",
    "    train_ds = train_ds.map(lambda sample: preprocess(sample))\n",
    "    valid_ds = valid_ds.map(lambda sample: preprocess(sample))\n",
    "    \n",
    "    train_ds = train_ds.shuffle(1024).batch(BATCH_SIZE).prefetch(1)\n",
    "    valid_ds = valid_ds.batch(BATCH_SIZE).prefetch(1)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04587b13-e9ea-41aa-9b96-c335a2366628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check dataset\n",
    "def plot_imgs(batch, num_rows=2, num_cols=6):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i in range(num_cols * num_rows):\n",
    "        ax = plt.subplot(num_rows, num_cols, i + 1)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(batch[i], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "test_ds, _ = get_datasets()\n",
    "test_batch = next(test_ds.as_numpy_iterator())\n",
    "print('Images:')\n",
    "plot_imgs(test_batch['image'])\n",
    "print('Labels')\n",
    "plot_imgs(test_batch['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43311f-62e7-48d6-b1df-d7be3e936b98",
   "metadata": {},
   "source": [
    "## 2. Build the PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc01f21-ec8a-425a-be9d-de3978047674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(nn.Module):\n",
    "    in_features: int # The number of input features\n",
    "    out_features: int # The number of output features\n",
    "    kernel_size: tuple\n",
    "    mask_type: str\n",
    "    padding: str\n",
    "\n",
    "    def setup(self):\n",
    "        assert self.mask_type in ['A', 'B'], 'Mask type should be either A or B'\n",
    "        kh, kw = self.kernel_size\n",
    "\n",
    "        # Generating mask -> shape (k, k)\n",
    "        mask = jnp.ones(shape=self.kernel_size)\n",
    "        mask = mask.at[kh // 2 + 1:,].set(0)\n",
    "        mask = mask.at[kh // 2, kw // 2 + 1:].set(0)\n",
    "        \n",
    "        if self.mask_type == 'A':\n",
    "            mask = mask.at[kh // 2, kw // 2].set(0)\n",
    "        # Expanding and repeating the mask -> shape (k, k, in_features, out_features)\n",
    "        mask = mask[..., None, None]\n",
    "        mask = jnp.tile(mask, (1, 1, self.in_features, self.out_features))\n",
    "        \n",
    "        self.conv = nn.Conv(features=self.out_features, \n",
    "                            kernel_size=self.kernel_size, \n",
    "                            padding=self.padding, \n",
    "                            mask=mask)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c941b4-d36b-4c00-876f-611d6af1cd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                      MaskedConv2D Summary                                      \u001b[0m\n",
      "┏━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                    \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│      │ MaskedConv2D │ \u001b[2mfloat32\u001b[0m[1,16,16,1] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │                            │\n",
      "├──────┼──────────────┼────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ conv │ Conv         │ \u001b[2mfloat32\u001b[0m[1,16,16,1] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ bias: \u001b[2mfloat32\u001b[0m[128]         │\n",
      "│      │              │                    │                      │ kernel: \u001b[2mfloat32\u001b[0m[7,7,1,128] │\n",
      "│      │              │                    │                      │                            │\n",
      "│      │              │                    │                      │ \u001b[1m6,400 \u001b[0m\u001b[1;2m(25.6 KB)\u001b[0m            │\n",
      "├──────┼──────────────┼────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m6,400 \u001b[0m\u001b[1;2m(25.6 KB)\u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\n",
      "└──────┴──────────────┴────────────────────┴──────────────────────┴────────────────────────────┘\n",
      "\u001b[1m                                                                                                \u001b[0m\n",
      "\u001b[1m                               Total Parameters: 6,400 \u001b[0m\u001b[1;2m(25.6 KB)\u001b[0m\u001b[1m                                \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check masked conv\n",
    "masked_conv = MaskedConv2D(1, 128, (7, 7), 'A', 'SAME')\n",
    "print(masked_conv.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 16, 16, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894abf2f-f176-454c-adb1-f180dfc8eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    features:int\n",
    "    \n",
    "    def setup(self):\n",
    "        \n",
    "        self.conv_1 = nn.Sequential([\n",
    "                        nn.Conv(features=self.features // 2, \n",
    "                              kernel_size=(1, 1),\n",
    "                              strides=1),\n",
    "                        nn.relu])\n",
    "        \n",
    "        self.pixel_conv = nn.Sequential([\n",
    "                            MaskedConv2D(in_features=self.features // 2,\n",
    "                                   out_features=self.features // 2,\n",
    "                                   kernel_size=(3, 3),\n",
    "                                   mask_type='B',\n",
    "                                   padding='SAME'),\n",
    "                            nn.relu])\n",
    "\n",
    "        self.conv_2 = nn.Sequential([\n",
    "                        nn.Conv(features=self.features,\n",
    "                              kernel_size=(1, 1),\n",
    "                              strides=1),\n",
    "                        nn.relu])\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        conv_x = self.conv_1(x)\n",
    "        conv_x = self.pixel_conv(conv_x)\n",
    "        conv_x = self.conv_2(conv_x)\n",
    "        return conv_x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14e142d2-4796-45c7-9495-27903cf1c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check residual block\n",
    "# res_block = ResidualBlock(128) \n",
    "# print(res_block.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 16, 16, 128))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a364236-2389-4f93-92d9-a1f967a04b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "\n",
    "    in_channels:int\n",
    "    num_filters:int\n",
    "    num_res_blocks:int\n",
    "    output_size:int\n",
    "    \n",
    "    def setup(self):\n",
    "\n",
    "        self.masked_conv_1 = nn.Sequential([\n",
    "                                MaskedConv2D(in_features=self.in_channels, \n",
    "                                             out_features=self.num_filters,\n",
    "                                             kernel_size=(7, 7),\n",
    "                                             mask_type='A',\n",
    "                                             padding='SAME'),\n",
    "                                nn.relu])\n",
    "\n",
    "        self.res_blocks = nn.Sequential([\n",
    "                                ResidualBlock(self.num_filters) \n",
    "                                    for _ in range(self.num_res_blocks)])\n",
    "\n",
    "        masked_conv_2_layers = []\n",
    "        for _ in range(2):\n",
    "            masked_conv_2_layers.append(MaskedConv2D(in_features=self.num_filters,\n",
    "                                                out_features=self.num_filters,\n",
    "                                                kernel_size=(1, 1),\n",
    "                                                mask_type='B',\n",
    "                                                padding='VALID'))\n",
    "            masked_conv_2_layers.append(nn.relu)\n",
    "\n",
    "        self.masked_conv_2 = nn.Sequential(masked_conv_2_layers)\n",
    "\n",
    "        self.output_conv = nn.Conv(features=self.output_size,\n",
    "                                   kernel_size=(1, 1),\n",
    "                                   padding='VALID')\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.masked_conv_1(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.masked_conv_2(x)\n",
    "        x = self.output_conv(x)\n",
    "        return x.reshape(x.shape[0], \n",
    "                         x.shape[1], \n",
    "                         x.shape[2], \n",
    "                         self.in_channels,\n",
    "                         self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e005b975-d25a-4a37-9074-39f654a8c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                               PixelCNN Summary                                               \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams               \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│                      │ PixelCNN      │ \u001b[2mfloat32\u001b[0m[1,16,16,1]   │ \u001b[2mfloat32\u001b[0m[1,16,16,1,8] │                       │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ masked_conv_1        │ Sequential    │ \u001b[2mfloat32\u001b[0m[1,16,16,1]   │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │                       │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ masked_conv_1/layer… │ MaskedConv2D  │ \u001b[2mfloat32\u001b[0m[1,16,16,1]   │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m6,400 \u001b[0m\u001b[1;2m(25.6 KB)\u001b[0m       │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ res_blocks           │ Sequential    │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │                       │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ res_blocks/layers_0  │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m     │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ res_blocks/layers_1  │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m     │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ res_blocks/layers_2  │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m     │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ res_blocks/layers_3  │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m     │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ res_blocks/layers_4  │ ResidualBlock │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m53,504 \u001b[0m\u001b[1;2m(214.0 KB)\u001b[0m     │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ masked_conv_2        │ Sequential    │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │                       │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ masked_conv_2/layer… │ MaskedConv2D  │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m      │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ masked_conv_2/layer… │ MaskedConv2D  │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 KB)\u001b[0m      │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│ output_conv          │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16,16,128] │ \u001b[2mfloat32\u001b[0m[1,16,16,8]   │ bias: \u001b[2mfloat32\u001b[0m[8]      │\n",
      "│                      │               │                      │                      │ kernel:               │\n",
      "│                      │               │                      │                      │ \u001b[2mfloat32\u001b[0m[1,1,128,8]    │\n",
      "│                      │               │                      │                      │                       │\n",
      "│                      │               │                      │                      │ \u001b[1m1,032 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m        │\n",
      "├──────────────────────┼───────────────┼──────────────────────┼──────────────────────┼───────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m                    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m307,976 \u001b[0m\u001b[1;2m(1.2 MB)\u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m│\n",
      "└──────────────────────┴───────────────┴──────────────────────┴──────────────────────┴───────────────────────┘\n",
      "\u001b[1m                                                                                                              \u001b[0m\n",
      "\u001b[1m                                      Total Parameters: 307,976 \u001b[0m\u001b[1;2m(1.2 MB)\u001b[0m\u001b[1m                                      \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check PixelCNN model\n",
    "pixel_cnn = PixelCNN(CHANNELS, N_FILTERS, RESIDUAL_BLOCKS, PIXEL_LEVELS)\n",
    "print(pixel_cnn.tabulate(jax.random.PRNGKey(0), jnp.ones((1, 16, 16, 1)), depth=2,\n",
    "                         console_kwargs={'width': 110}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4a90a-8878-4272-9eec-b936ed47aee2",
   "metadata": {},
   "source": [
    "## 3. Functions for `Train State`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f52cf99e-ea5e-49be-8a1f-5f46c83c2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    loss: metrics.Average.from_output('loss')\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "\n",
    "def create_train_state(model, param_key, learning_rate):\n",
    "    # initialize model parameters\n",
    "    params = model.init(param_key, jnp.ones((BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)))['params']\n",
    "    # initialize optimizer\n",
    "    tx = optax.adam(learning_rate=LR)\n",
    "    return TrainState.create(\n",
    "                apply_fn=model.apply,\n",
    "                params=params,\n",
    "                tx=tx,\n",
    "                metrics=Metrics.empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0074c1-7db9-45a4-b110-d13a69b5a34a",
   "metadata": {},
   "source": [
    "## 4. Train step functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ebe7920-3c9f-45f2-9340-2a88d343ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        preds = state.apply_fn({'params': params}, batch['image'])\n",
    "        # preds = preds.reshape(-1, PIXEL_LEVELS)\n",
    "        # targets = batch['label'].reshape(-1)\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(preds, batch['label']).mean()\n",
    "        return loss\n",
    "\n",
    "    # compute loss and apply gradients\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    # update metrics\n",
    "    metric_updates = state.metrics.single_from_model_output(loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    \n",
    "    return state\n",
    "\n",
    "    \n",
    "# Validation\n",
    "@jax.jit\n",
    "def validation(state, batch):\n",
    "    preds = state.apply_fn({'params': state.params}, batch['image'])\n",
    "    # preds = preds.reshape(-1, PIXEL_LEVELS)\n",
    "    # targets = batch['label'].reshape(-1)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(preds, batch['label']).mean()\n",
    "\n",
    "    # update metrics\n",
    "    metric_updates = state.metrics.single_from_model_output(loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d79af8b8-2e12-4638-87d5-e083d878c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for sequential image generation\n",
    "@jax.jit\n",
    "def model_output_probs(state, output_img):\n",
    "    preds = state.apply_fn({'params': state.params}, output_img)\n",
    "    return nn.log_softmax(preds)\n",
    "\n",
    "\n",
    "def sample_from(probs, temperature):\n",
    "    probs = np.array(probs, dtype=float) # Avoid numpy's \"probs do not sum to 1 problem\"\n",
    "    probs = probs ** (1.0 / temperature)\n",
    "    probs /= probs.sum()\n",
    "    return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "\n",
    "def generate_imgs(state, temperature, num_imgs):\n",
    "\n",
    "    output_imgs = np.zeros((num_imgs, IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "    batch, rows, cols, channels = output_imgs.shape\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            for channel in range(channels):\n",
    "                preds = model_output_probs(state, output_imgs)[:, row, col, channel].squeeze() ### fix this in pytorch\n",
    "                output_imgs[:, row, col, channel] = [sample_from(x, temperature) for x in preds]\n",
    "                output_imgs[:, row, col, channel] /= PIXEL_LEVELS\n",
    "    return output_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9db09-6de6-4f09-831e-a4f9a9d4b9ec",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed723444-b21c-41e5-b22c-cb0470ddaf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn = PixelCNN(CHANNELS, N_FILTERS, RESIDUAL_BLOCKS, PIXEL_LEVELS)\n",
    "state = create_train_state(pixel_cnn, jax.random.PRNGKey(0), learning_rate=LR)\n",
    "train_ds, valid_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4d67a6a6-0af7-4fc3-9ec3-2ed2bf7c5e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1\tTime:0.10 min\n",
      "\tTrain loss: 0.7227  Valid loss: 0.6329\n",
      "Epoch   5\tTime:0.06 min\n",
      "\tTrain loss: 0.5837  Valid loss: 0.5827\n",
      "Epoch  10\tTime:0.06 min\n",
      "\tTrain loss: 0.5631  Valid loss: 0.5688\n",
      "Epoch  15\tTime:0.06 min\n",
      "\tTrain loss: 0.5538  Valid loss: 0.5609\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mas_numpy_iterator():\n\u001b[0;32m----> 7\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mcompute()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreplace(metrics\u001b[38;5;241m=\u001b[39mstate\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mempty())\n",
      "File \u001b[0;32m~/miniconda3/envs/GDL_JAX/lib/python3.9/site-packages/flax/core/frozen_dict.py:162\u001b[0m, in \u001b[0;36mFrozenDict.tree_unflatten\u001b[0;34m(cls, keys, values)\u001b[0m\n\u001b[1;32m    157\u001b[0m   sorted_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict)\n\u001b[1;32m    158\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    159\u001b[0m       [(jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mDictKey(k), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict[k]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m sorted_keys]\n\u001b[1;32m    160\u001b[0m   ), \u001b[38;5;28mtuple\u001b[39m(sorted_keys)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_unflatten\u001b[39m(\u001b[38;5;28mcls\u001b[39m, keys, values):\n\u001b[1;32m    164\u001b[0m   \u001b[38;5;66;03m# data is already deep copied due to tree map mechanism\u001b[39;00m\n\u001b[1;32m    165\u001b[0m   \u001b[38;5;66;03m# we can skip the deep copy in the constructor\u001b[39;00m\n\u001b[1;32m    166\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m({k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, values)}, __unsafe_skip_copy__\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "\n",
    "    prev_time = time.time()\n",
    "    \n",
    "    # training\n",
    "    for batch in train_ds.as_numpy_iterator():\n",
    "        state = train_step(state, batch)\n",
    "    \n",
    "    train_loss = state.metrics.compute()['loss']\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    # validation\n",
    "    test_state = state\n",
    "    for batch in valid_ds.as_numpy_iterator():\n",
    "        test_state = validation(test_state, batch)\n",
    "\n",
    "    valid_loss = test_state.metrics.compute()['loss']\n",
    "\n",
    "    curr_time = time.time()\n",
    "    if i == 0 or (i + 1) % 5 == 0:\n",
    "        print(f'Epoch {i+1:3d}\\tTime:{(curr_time - prev_time) / 60:.2f} min')\n",
    "        print(f'\\tTrain loss: {train_loss:.4f}  Valid loss: {valid_loss:.4f}')\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        output_imgs = generate_imgs(state, 1.0, 12)\n",
    "        plot_imgs(output_imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64472a2-34c2-40b5-a5e9-5d0418779bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b05dc-176f-49ac-a130-4c2c807103b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
