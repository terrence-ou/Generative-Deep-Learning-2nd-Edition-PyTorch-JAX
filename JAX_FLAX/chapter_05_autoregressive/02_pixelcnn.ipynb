{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb77744-578c-4b3e-9507-104e361021cb",
   "metadata": {},
   "source": [
    "# PixelCNN for FashionMNIST\n",
    "\n",
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/02_pixelcnn/pixelcnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0648c9-19ba-4f25-b5a8-73e36dcb4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec6a3f-fdfd-4f37-825b-aac09f03e764",
   "metadata": {},
   "source": [
    "## 0. Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4db859-14a6-4ca3-a9c8-256976003447",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "PIXEL_LEVELS = 8\n",
    "N_FILTERS = 128\n",
    "RESIDUAL_BLOCKS = 5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce902e-fd78-403a-b4a3-7a90e49e255d",
   "metadata": {},
   "source": [
    "## 1. Preparing FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a84e3f0-154b-4ff7-a0d5-3917d9546e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn input image into pixels and per-pixel labels\n",
    "def preprocess(imgs):\n",
    "    imgs = imgs['image']\n",
    "    imgs_int = tf.image.resize(imgs, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    imgs_int = tf.cast((imgs_int / (256 / PIXEL_LEVELS)), tf.int32)\n",
    "    imgs = tf.cast(imgs_int, tf.float32)\n",
    "    imgs = imgs / PIXEL_LEVELS\n",
    "    return {'image': imgs, 'label': imgs_int}\n",
    "\n",
    "# Get train/valid datasets\n",
    "def get_datasets():\n",
    "    train_ds, valid_ds = tfds.load('fashion_mnist', split=['train', 'test'])\n",
    "    \n",
    "    train_ds = train_ds.map(lambda sample: preprocess(sample))\n",
    "    valid_ds = valid_ds.map(lambda sample: preprocess(sample))\n",
    "    \n",
    "    train_ds = train_ds.shuffle(1024).batch(BATCH_SIZE).prefetch(1)\n",
    "    valid_ds = valid_ds.batch(BATCH_SIZE).prefetch(1)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04587b13-e9ea-41aa-9b96-c335a2366628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check dataset\n",
    "def plot_imgs(batch, num_rows=2, num_cols=6):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i in range(num_cols * num_rows):\n",
    "        ax = plt.subplot(num_rows, num_cols, i + 1)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(batch[i], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "test_ds, _ = get_datasets()\n",
    "test_batch = next(test_ds.as_numpy_iterator())['image']\n",
    "plot_imgs(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43311f-62e7-48d6-b1df-d7be3e936b98",
   "metadata": {},
   "source": [
    "## 2. Build the PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8dc01f21-ec8a-425a-be9d-de3978047674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(nn.Module):\n",
    "    in_features: int # The number of input features\n",
    "    out_features: int # The number of output features\n",
    "    kernel_size: tuple\n",
    "    mask_type: str\n",
    "    padding: str\n",
    "\n",
    "    def setup(self):\n",
    "        assert self.mask_type in ['A', 'B'], 'Mask type should be either A or B'\n",
    "        kh, kw = self.kernel_size\n",
    "\n",
    "        # Generating mask -> shape (k, k)\n",
    "        mask = jnp.ones(shape=self.kernel_size)\n",
    "        mask = mask.at[kh // 2 + 1:,].set(0)\n",
    "        mask = mask.at[kh // 2, kw // 2 + 1:].set(0)\n",
    "\n",
    "        if self.mask_type == 'A':\n",
    "            mask = mask.at[kh // 2, kw // 2].set(0)\n",
    "            \n",
    "        # Expanding and repeating the mask -> shape (k, k, in_features, out_features)\n",
    "        mask = mask[:, :, None, None]\n",
    "        mask = jnp.tile(mask, (1, 1, self.in_features, self.out_features))\n",
    "        \n",
    "        self.conv = nn.Conv(features=self.out_features, \n",
    "                            kernel_size=self.kernel_size, \n",
    "                            padding=self.padding, \n",
    "                            mask=mask)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.conv(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
