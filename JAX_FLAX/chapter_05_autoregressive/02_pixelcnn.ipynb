{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb77744-578c-4b3e-9507-104e361021cb",
   "metadata": {},
   "source": [
    "# PixelCNN for FashionMNIST\n",
    "\n",
    "**The notebook has been adapted from the notebook provided in David Foster's Generative Deep Learning, 2nd Edition.**\n",
    "\n",
    "- Book: [Amazon](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1098134184/ref=sr_1_1?keywords=generative+deep+learning%2C+2nd+edition&qid=1684708209&sprefix=generative+de%2Caps%2C93&sr=8-1)\n",
    "- Original notebook (tensorflow and keras): [Github](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/05_autoregressive/02_pixelcnn/pixelcnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0648c9-19ba-4f25-b5a8-73e36dcb4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec6a3f-fdfd-4f37-825b-aac09f03e764",
   "metadata": {},
   "source": [
    "## 0. Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4db859-14a6-4ca3-a9c8-256976003447",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "PIXEL_LEVELS = 8\n",
    "N_FILTERS = 128\n",
    "RESIDUAL_BLOCKS = 5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce902e-fd78-403a-b4a3-7a90e49e255d",
   "metadata": {},
   "source": [
    "## 1. Preparing FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a84e3f0-154b-4ff7-a0d5-3917d9546e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn input image into pixels and per-pixel labels\n",
    "def preprocess(imgs):\n",
    "    imgs = imgs['image']\n",
    "    imgs_int = tf.image.resize(imgs, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    imgs_int = tf.cast((imgs_int / (256 / PIXEL_LEVELS)), tf.int32)\n",
    "    imgs = tf.cast(imgs_int, tf.float32)\n",
    "    imgs = imgs / PIXEL_LEVELS\n",
    "    return {'image': imgs, 'label': imgs_int}\n",
    "\n",
    "# Get train/valid datasets\n",
    "def get_datasets():\n",
    "    train_ds, valid_ds = tfds.load('fashion_mnist', split=['train', 'test'])\n",
    "    \n",
    "    train_ds = train_ds.map(lambda sample: preprocess(sample))\n",
    "    valid_ds = valid_ds.map(lambda sample: preprocess(sample))\n",
    "    \n",
    "    train_ds = train_ds.shuffle(1024).batch(BATCH_SIZE).prefetch(1)\n",
    "    valid_ds = valid_ds.batch(BATCH_SIZE).prefetch(1)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04587b13-e9ea-41aa-9b96-c335a2366628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check dataset\n",
    "def plot_imgs(batch, num_rows=2, num_cols=6):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for i in range(num_cols * num_rows):\n",
    "        ax = plt.subplot(num_rows, num_cols, i + 1)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(batch[i], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "test_ds, _ = get_datasets()\n",
    "test_batch = next(test_ds.as_numpy_iterator())['image']\n",
    "plot_imgs(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43311f-62e7-48d6-b1df-d7be3e936b98",
   "metadata": {},
   "source": [
    "## 2. Build the PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc01f21-ec8a-425a-be9d-de3978047674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(nn.Module):\n",
    "    in_features: int # The number of input features\n",
    "    out_features: int # The number of output features\n",
    "    kernel_size: tuple\n",
    "    mask_type: str\n",
    "    padding: str\n",
    "\n",
    "    def setup(self):\n",
    "        assert self.mask_type in ['A', 'B'], 'Mask type should be either A or B'\n",
    "        kh, kw = self.kernel_size\n",
    "\n",
    "        # Generating mask -> shape (k, k)\n",
    "        mask = jnp.ones(shape=self.kernel_size)\n",
    "        mask = mask.at[kh // 2 + 1:,].set(0)\n",
    "        mask = mask.at[kh // 2, kw // 2 + 1:].set(0)\n",
    "\n",
    "        if self.mask_type == 'A':\n",
    "            mask = mask.at[kh // 2, kw // 2].set(0)\n",
    "            \n",
    "        # Expanding and repeating the mask -> shape (k, k, in_features, out_features)\n",
    "        mask = mask[:, :, None, None]\n",
    "        mask = jnp.tile(mask, (1, 1, self.in_features, self.out_features))\n",
    "        \n",
    "        self.conv = nn.Conv(features=self.out_features, \n",
    "                            kernel_size=self.kernel_size, \n",
    "                            padding=self.padding, \n",
    "                            mask=mask)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894abf2f-f176-454c-adb1-f180dfc8eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def setup(self, features):\n",
    "\n",
    "        self.conv_1 = nn.Sequential([\n",
    "                        nn.Conv(features=features // 2, \n",
    "                              kernel_size=(1, 1),\n",
    "                              strides=1),\n",
    "                        nn.relu])\n",
    "        \n",
    "        self.pixel_conv = nn.Sequential([\n",
    "                            MaskedConv2D(in_features=features // 2,\n",
    "                                       out_features=features // 2,\n",
    "                                       kernel_size=(3, 3),\n",
    "                                       mask_type='B',\n",
    "                                       padding='same'),\n",
    "                            nn.relu])\n",
    "\n",
    "        self.conv_2 = nn.Sequential([\n",
    "                        nn.Conv(features=features,\n",
    "                              kernel_size=(1, 1),\n",
    "                              strides=1),\n",
    "                        nn.relu])\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c87e3-1c4d-4cba-8ed6-a2bc1d591396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
